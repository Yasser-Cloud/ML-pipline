{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19de2c45-84cc-453e-bdcb-84e2ca54870a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook use an ensemble machine learning approach for classification. I train different models on different samples and get the average result of the predictions. Each model is a pipeline that consists of several steps. I use 5000 test samples with balanced classes to evaluate the performance of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JWVUM61bG31-",
   "metadata": {
    "id": "JWVUM61bG31-"
   },
   "source": [
    "## Reading and exploration the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "724fd63d-d896-418c-8dbe-3f537559e5a1",
   "metadata": {
    "id": "724fd63d-d896-418c-8dbe-3f537559e5a1"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_row', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b66ea3c-3bcc-4d61-b570-f06c5b12bc35",
   "metadata": {
    "id": "5b66ea3c-3bcc-4d61-b570-f06c5b12bc35"
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('ar_reviews_100k.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120da66b-0b88-4a56-ad09-cb367eef6192",
   "metadata": {
    "id": "120da66b-0b88-4a56-ad09-cb367eef6192"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59756</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>أمازلت تنامين على صوت ماجدة الرومي وتقولين لصوتها المنبعث من الراديو:. غن. غن يا ماجدة فلولا صوتك، لشعرت كم أنا وحيدة. وكم هن النساء بلا قلوب ... غن غن يا ماجدة، وليأت المطر والصحف اليومية والقهوة والحب والكلمات. ولأقول لكل النساء دمتن وافرات الظل وجميلات. ومن قلبي سلام لكل ولئك الذين لم يكبروا. ولن يكبروا إلى أكثر مما وصلوا إليه. الذين خطف الرصاص بصرهم مبكرا. إلى العصافير فوق وتحت كل ذرة تراب من الوطن. بإسم المطر ، والرقص .... بإسم البحر ، والذهول الأول .... اسميك نشيدي. وأنحني. كلما إنتهيت من قصيدة.. ما حلمك يا أبي:. أن أصلي الفجر في القدس، أطير لبيروت أسرق حجرا، أطير لدمشق أسرق وردة، أطير لبغداد أسرق كتابا، أطير لنيل القاهرة أسرق أغنية، أطير لفاس أسرق نقشا، أطير لتونس أسرق حمامة.. أحط في الجزائر، فتسرقني</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80409</th>\n",
       "      <td>Negative</td>\n",
       "      <td>ضعيف جدا. لا كان السرير مزعج جدا. المكيف جدا حار و عند اخبار الطاقم لثلاث مرات لم يتجاوبو و لم يصلحوا الخلل، وكانت الغرفه جدا سيئة و رائحتها غير لائقه و بعدها خرجت من الفندق وحجز فندق اخر تقيمي العام من عشرهالفندق سئ جدا</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56291</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>مع إني أحب الرسائل وقراءتها جدا الا أنني لم أحب تحببه وتذلله لها في البداية. قصيرة ومبتورة لو اتبعت بردود غادة له لكان أفضل. الرسائل الأخيرة لإخته فائزة أصابتني في مقتل .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35288</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>تم تغيير الغرفه الي الغرفه المطلوبه بعد جهد وقد تكررت هذه الحاله اكثر من مره . قربه من الحرم. لا يعترفون بنوع حجز الغرفه اي نوع السرير وكذاك المكان طلب لغير المدخنين</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11534</th>\n",
       "      <td>Positive</td>\n",
       "      <td>مش هقدر اكتب ريفيو منصف للرواية لانى عندى افكار مختلطة حاليا بس اقدر اقول ان البداية خلت سقف توقعاتى عالى ويمكن عشان كده باقى ارواية وان كان جيد ولكن لم يكن المنشود بالنسبة لى. الحبكة الى حد بعيد جيدة ولكن عابها الاستطراد الممل فى غير موضع واسلوب د/عزالدين ليس الاسلوب الادبى المعتاد من كتاب كبار ك د/احمد خالد توفيق. مما يميز الرواية هو مضمونها واهمية ما تطرحه وبالتالى لا يوجد ادنى خسارة من قراءتها بلى على العكس ممكن ان تكون اسقراء للقادم وتحذير منه. ده رايى المبدئى عن الرواية :</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label  \\\n",
       "59756     Mixed   \n",
       "80409  Negative   \n",
       "56291     Mixed   \n",
       "35288     Mixed   \n",
       "11534  Positive   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \n",
       "59756  أمازلت تنامين على صوت ماجدة الرومي وتقولين لصوتها المنبعث من الراديو:. غن. غن يا ماجدة فلولا صوتك، لشعرت كم أنا وحيدة. وكم هن النساء بلا قلوب ... غن غن يا ماجدة، وليأت المطر والصحف اليومية والقهوة والحب والكلمات. ولأقول لكل النساء دمتن وافرات الظل وجميلات. ومن قلبي سلام لكل ولئك الذين لم يكبروا. ولن يكبروا إلى أكثر مما وصلوا إليه. الذين خطف الرصاص بصرهم مبكرا. إلى العصافير فوق وتحت كل ذرة تراب من الوطن. بإسم المطر ، والرقص .... بإسم البحر ، والذهول الأول .... اسميك نشيدي. وأنحني. كلما إنتهيت من قصيدة.. ما حلمك يا أبي:. أن أصلي الفجر في القدس، أطير لبيروت أسرق حجرا، أطير لدمشق أسرق وردة، أطير لبغداد أسرق كتابا، أطير لنيل القاهرة أسرق أغنية، أطير لفاس أسرق نقشا، أطير لتونس أسرق حمامة.. أحط في الجزائر، فتسرقني  \n",
       "80409                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ضعيف جدا. لا كان السرير مزعج جدا. المكيف جدا حار و عند اخبار الطاقم لثلاث مرات لم يتجاوبو و لم يصلحوا الخلل، وكانت الغرفه جدا سيئة و رائحتها غير لائقه و بعدها خرجت من الفندق وحجز فندق اخر تقيمي العام من عشرهالفندق سئ جدا  \n",
       "56291                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    مع إني أحب الرسائل وقراءتها جدا الا أنني لم أحب تحببه وتذلله لها في البداية. قصيرة ومبتورة لو اتبعت بردود غادة له لكان أفضل. الرسائل الأخيرة لإخته فائزة أصابتني في مقتل .  \n",
       "35288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         تم تغيير الغرفه الي الغرفه المطلوبه بعد جهد وقد تكررت هذه الحاله اكثر من مره . قربه من الحرم. لا يعترفون بنوع حجز الغرفه اي نوع السرير وكذاك المكان طلب لغير المدخنين  \n",
       "11534                                                                                                                                                                                                                                            مش هقدر اكتب ريفيو منصف للرواية لانى عندى افكار مختلطة حاليا بس اقدر اقول ان البداية خلت سقف توقعاتى عالى ويمكن عشان كده باقى ارواية وان كان جيد ولكن لم يكن المنشود بالنسبة لى. الحبكة الى حد بعيد جيدة ولكن عابها الاستطراد الممل فى غير موضع واسلوب د/عزالدين ليس الاسلوب الادبى المعتاد من كتاب كبار ك د/احمد خالد توفيق. مما يميز الرواية هو مضمونها واهمية ما تطرحه وبالتالى لا يوجد ادنى خسارة من قراءتها بلى على العكس ممكن ان تكون اسقراء للقادم وتحذير منه. ده رايى المبدئى عن الرواية :  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15565ad8-9441-4180-a68b-108fc1aed1c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "15565ad8-9441-4180-a68b-108fc1aed1c6",
    "outputId": "8d772cdb-945b-492f-990c-7bdf167d6f9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bb9a4a56-5e5a-4b0f-bcd6-f8d4188665f3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>99999</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشاطيء. المطعم</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>33333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb9a4a56-5e5a-4b0f-bcd6-f8d4188665f3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bb9a4a56-5e5a-4b0f-bcd6-f8d4188665f3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bb9a4a56-5e5a-4b0f-bcd6-f8d4188665f3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           label                                                       text\n",
       "count      99999                                                      99999\n",
       "unique         3                                                      99999\n",
       "top     Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشاطيء. المطعم\n",
       "freq       33333                                                          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b7140ae-4298-416b-a24b-73672567a17f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7b7140ae-4298-416b-a24b-73672567a17f",
    "outputId": "2d65f182-f824-4105-9358-9f859068d5cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    33333\n",
       "Mixed       33333\n",
       "Negative    33333\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bBUtpKLWHcHH",
   "metadata": {
    "id": "bBUtpKLWHcHH"
   },
   "source": [
    "Data is balanced and no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c406e7-ff2b-4d07-8c8a-f151773adb2e",
   "metadata": {
    "id": "f4c406e7-ff2b-4d07-8c8a-f151773adb2e",
    "tags": []
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tOaB1C1zkfKj",
   "metadata": {
    "id": "tOaB1C1zkfKj"
   },
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "#To convert leabels to int for some models\n",
    "  return df['label'].replace({'Positive': 2, 'Negative': 1,'Mixed': 0}).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nxJdkW3aH4_B",
   "metadata": {
    "id": "nxJdkW3aH4_B"
   },
   "source": [
    "Try different ways for preprocessing like stemming and removing stop words not help, they get down the accuracy so I remove maybe some critical terms like \"ﻻ\" to make the meaning different remove in the process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pWUVxFLuMfSY",
   "metadata": {
    "id": "pWUVxFLuMfSY"
   },
   "source": [
    "## Baseline model (using pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d9da0a-fbfa-44e1-882c-7d52d54b0664",
   "metadata": {
    "id": "e3d9da0a-fbfa-44e1-882c-7d52d54b0664"
   },
   "outputs": [],
   "source": [
    "#Note here I don't use the random seed to get more sense about data every train and train on many samples \n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(reviews.text, reviews.label, test_size=0.05, \n",
    "                                                    stratify=reviews.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b3dd3d-53fa-4f4b-b962-14492533e39c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8b3dd3d-53fa-4f4b-b962-14492533e39c",
    "outputId": "be20d4ad-da95-4be8-85db-aab5b11ef6c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Build pipe using CountVectorizer and LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vec = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train1,y_train1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0767fd7d-e637-4b69-b58e-5243c8a7c1ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0767fd7d-e637-4b69-b58e-5243c8a7c1ee",
    "outputId": "c0abf860-525a-4f1f-91d1-d597ab6b2db3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mixed       0.58      0.52      0.55      1667\n",
      "    Negative       0.71      0.70      0.71      1666\n",
      "    Positive       0.64      0.72      0.68      1667\n",
      "\n",
      "    accuracy                           0.65      5000\n",
      "   macro avg       0.65      0.65      0.64      5000\n",
      "weighted avg       0.65      0.65      0.64      5000\n",
      "\n",
      "accuracy: 0.647\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe, x_test, y_test):\n",
    "#To print classification report\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe, X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nFismiDQyMPX",
   "metadata": {
    "id": "nFismiDQyMPX"
   },
   "outputs": [],
   "source": [
    "# Another set of samples\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(reviews.text, reviews.label, test_size=0.05, \n",
    "                                                    stratify=reviews.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "829027d4-4b59-4c6f-a515-0faa7b90cb57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "829027d4-4b59-4c6f-a515-0faa7b90cb57",
    "outputId": "dfff4c36-87bb-4c2b-ece6-a2131040953e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01, ngram_range=(3, 5))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='char_wb', max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build pipe_tfidf using TfidfVectorizer and LogisticRegression\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=.01, max_df=.3)\n",
    "clf = LogisticRegression()\n",
    "pipe_tfidf = make_pipeline(vec, clf)\n",
    "pipe_tfidf.fit(X_train2,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e8c29f-96dd-4634-9448-e9ffd9a964c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03e8c29f-96dd-4634-9448-e9ffd9a964c1",
    "outputId": "3853ba62-9f6e-4a80-a789-f6a4c2d1356a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mixed       0.62      0.56      0.59      1666\n",
      "    Negative       0.70      0.74      0.72      1667\n",
      "    Positive       0.71      0.74      0.72      1667\n",
      "\n",
      "    accuracy                           0.68      5000\n",
      "   macro avg       0.68      0.68      0.68      5000\n",
      "weighted avg       0.68      0.68      0.68      5000\n",
      "\n",
      "accuracy: 0.680\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe_tfidf, X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ESi6VgX-UCyS",
   "metadata": {
    "id": "ESi6VgX-UCyS"
   },
   "source": [
    "### Some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adbbe2ba-e227-4d72-a30e-cf094d34a629",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adbbe2ba-e227-4d72-a30e-cf094d34a629",
    "outputId": "f376a989-44d1-4f62-b387-b8ae81e745c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf.predict(['احلي مطعم في الدنيا'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "S4NzZXJAS819",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4NzZXJAS819",
    "outputId": "dcbf9006-f8d6-4eee-bb49-6743998affb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(['اسوء مطعم في الدنيا'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "VlHEpX6SVh70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "VlHEpX6SVh70",
    "outputId": "4e267638-0f0e-4875-f510-9ae89cc8cae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label: Negative\n",
      "احد أقل كتب الدكتور احمد ..... مقدرتش افهم ايه الفكره او ايه المقصود من الكتاب كقصه يعتبر مقبول جدا جاد لكن لو في فكره مقصوده من الكتاب فهي فعلا ضلت الطريق الى عقلي ...او انني لم ارتق لأفهمها\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Negative'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "true label: Mixed\n",
      "عبارة عن قصيدة تدور عن عبد لبنى الحسحاس اسمة سحيم تم قتله حرقا لتغزله في نساء القبيلة ويعيد القصيبي احياء الحكاية عن طريق قصيدته مع تطعيمها ببعض ابيات الشعر من تأليف سحيم نفسة\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Mixed'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "true label: Mixed\n",
      "كل من لا يلتبس عليه الوضع السوري. يصبح مطعونا بمصداقيته. وكل من يبرر لظالم هو جاهل. وكل من يتعطش للفوضى هو مغامر. وكل من لا يصرخ بصوت أعلى من صوت السلفية. ليس بثائر حقيقي. لأن الحرية والثورة. لن تكونا على يد سلفية ولا عشائرية ولا رجعية. ستعيدنا مئات السنين إلى الوراء. ...من لم يحرر نفسه لا يستطيع أن يحرر وطنه. هكذا وصفت الكاتبة الثورة السورية حتى عام . أي ما قبل تفشي الداعشية. ثورة لها وجوه كثيرة. ورئيس له وجوه اخرى. فكتبت قانونها الاول:. أكره الجميع وأحب سوريا . حاولت ان لا تنتق لنفسها موقفا ولا موقعا ولا خطوطا حمراء. فوجدها البعض أنها ربما فقدت المصداقية. وبعد عامين من الطبعة الأولى. نردد معها ذات العبارة:. لا نريد حرية على شكل تقسيم. لكن....أليس هناك سواها من حرية؟\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Negative'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "true label: Negative\n",
      "لن اكرر نزولي في فندق بول مان زمزم مكه . . الغرف ليسة نظيفه و الاثاث قديم و الصاله مطله على الحمامات و المطبخ و ليست مطله على الحرم\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Negative'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "true label: Positive\n",
      "محمود عزمي ... الشخصية المعقدة التي لا تجيد سوى جلد الذات. الابحار داخل محمود وصفحات حياته مرورا بالثورة العرابية ...الاحتلال الانجليزي ووصف الاجواء السياسية وقتها. نقلا لواحة سيوة وواقع مختلف وتفكير وعادات نجهل عنها الكثير. التحليق التاريخي المصاح للاحداث الاسكندر الاكبر واثار سيوة. في مهنيه وبراعة يجمع بهاء طاهر كل هذا في ملحمة ممتعة تستحق القراءة\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Positive'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _, row in reviews.sample(5).iterrows():\n",
    "    print(f\"true label: {row['label']}\")\n",
    "    print(row['text'])\n",
    "    display(pipe_tfidf.predict([row['text']]))\n",
    "    print(\"--\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a_Z7eoalbUf",
   "metadata": {
    "id": "3a_Z7eoalbUf"
   },
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(reviews.text, label_encode(reviews), test_size=0.05, \n",
    "                                                    stratify=label_encode(reviews))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924r99NWUQWz",
   "metadata": {
    "id": "924r99NWUQWz"
   },
   "source": [
    "## Improve the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "N8nAE0PyWoow",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "id": "N8nAE0PyWoow",
    "outputId": "01d57eb7-3282-44fe-eeb1-4d0590b90cd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=True, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=True, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective=&#x27;multi:softprob&#x27;, predictor=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01, ngram_range=(3, 5))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char_wb', max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                ('clf',\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=True, eval_metric=None,\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               objective='multi:softprob', predictor=None, ...))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try using xgboost to improve with GPUs to run fast\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Build the pipeline\n",
    "pipe_tfidf2 = Pipeline([('tfidf', TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=.01, max_df=.3)), ('clf', xgb.XGBClassifier(enable_categorical=True,tree_method='gpu_hist'))])\n",
    "\n",
    "pipe_tfidf2.fit(X_train3, y_train3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ieTf6oZsft7m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ieTf6oZsft7m",
    "outputId": "b99d1577-cf3a-4270-c88f-a363bacbafeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.11      0.15      1667\n",
      "           1       0.35      0.80      0.49      1666\n",
      "           2       0.33      0.09      0.14      1667\n",
      "\n",
      "    accuracy                           0.33      5000\n",
      "   macro avg       0.31      0.33      0.26      5000\n",
      "weighted avg       0.31      0.33      0.26      5000\n",
      "\n",
      "accuracy: 0.335\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe_tfidf2, X_test3, y_test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hwLejoPUUqdR",
   "metadata": {
    "id": "hwLejoPUUqdR"
   },
   "source": [
    "Give a poor result :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "_jdDHP7uhTwE",
   "metadata": {
    "id": "_jdDHP7uhTwE"
   },
   "outputs": [],
   "source": [
    "def proba(model,X_test):\n",
    "#To get probabilities for each class\n",
    "  return model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "_n8Fjhm42oQO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_n8Fjhm42oQO",
    "outputId": "4beff628-603c-4c95-fa87-3a004a41e273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-1.2\n"
     ]
    }
   ],
   "source": [
    "# install catboost\n",
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "JolMWL-I2omV",
   "metadata": {
    "id": "JolMWL-I2omV"
   },
   "outputs": [],
   "source": [
    "#Note here need to label_encode function and also with xgboot\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(reviews.text, label_encode(reviews), test_size=0.05, \n",
    "                                                    stratify=reviews.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "YljE6U_G2omX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YljE6U_G2omX",
    "outputId": "ad93692e-7df7-4c40-de3a-134842753c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.164338\n",
      "0:\tlearn: 1.0530846\ttotal: 419ms\tremaining: 6m 58s\n",
      "1:\tlearn: 1.0222771\ttotal: 650ms\tremaining: 5m 24s\n",
      "2:\tlearn: 0.9983011\ttotal: 874ms\tremaining: 4m 50s\n",
      "3:\tlearn: 0.9790112\ttotal: 1.09s\tremaining: 4m 31s\n",
      "4:\tlearn: 0.9628982\ttotal: 1.3s\tremaining: 4m 18s\n",
      "5:\tlearn: 0.9494355\ttotal: 1.5s\tremaining: 4m 8s\n",
      "6:\tlearn: 0.9384312\ttotal: 1.72s\tremaining: 4m 3s\n",
      "7:\tlearn: 0.9277454\ttotal: 1.93s\tremaining: 3m 59s\n",
      "8:\tlearn: 0.9190731\ttotal: 2.08s\tremaining: 3m 49s\n",
      "9:\tlearn: 0.9107079\ttotal: 2.25s\tremaining: 3m 42s\n",
      "10:\tlearn: 0.9029011\ttotal: 2.42s\tremaining: 3m 37s\n",
      "11:\tlearn: 0.8961816\ttotal: 2.57s\tremaining: 3m 31s\n",
      "12:\tlearn: 0.8896944\ttotal: 2.73s\tremaining: 3m 27s\n",
      "13:\tlearn: 0.8837161\ttotal: 2.91s\tremaining: 3m 25s\n",
      "14:\tlearn: 0.8786111\ttotal: 3.08s\tremaining: 3m 21s\n",
      "15:\tlearn: 0.8733914\ttotal: 3.25s\tremaining: 3m 19s\n",
      "16:\tlearn: 0.8687744\ttotal: 3.4s\tremaining: 3m 16s\n",
      "17:\tlearn: 0.8645149\ttotal: 3.58s\tremaining: 3m 15s\n",
      "18:\tlearn: 0.8598168\ttotal: 3.75s\tremaining: 3m 13s\n",
      "19:\tlearn: 0.8559242\ttotal: 3.9s\tremaining: 3m 11s\n",
      "20:\tlearn: 0.8520011\ttotal: 4.05s\tremaining: 3m 8s\n",
      "21:\tlearn: 0.8483876\ttotal: 4.21s\tremaining: 3m 7s\n",
      "22:\tlearn: 0.8452172\ttotal: 4.36s\tremaining: 3m 5s\n",
      "23:\tlearn: 0.8422138\ttotal: 4.52s\tremaining: 3m 3s\n",
      "24:\tlearn: 0.8392693\ttotal: 4.66s\tremaining: 3m 1s\n",
      "25:\tlearn: 0.8361413\ttotal: 4.82s\tremaining: 3m\n",
      "26:\tlearn: 0.8337255\ttotal: 4.99s\tremaining: 2m 59s\n",
      "27:\tlearn: 0.8312922\ttotal: 5.16s\tremaining: 2m 59s\n",
      "28:\tlearn: 0.8289253\ttotal: 5.3s\tremaining: 2m 57s\n",
      "29:\tlearn: 0.8267270\ttotal: 5.46s\tremaining: 2m 56s\n",
      "30:\tlearn: 0.8239676\ttotal: 5.6s\tremaining: 2m 55s\n",
      "31:\tlearn: 0.8214967\ttotal: 5.77s\tremaining: 2m 54s\n",
      "32:\tlearn: 0.8194627\ttotal: 5.92s\tremaining: 2m 53s\n",
      "33:\tlearn: 0.8174949\ttotal: 6.08s\tremaining: 2m 52s\n",
      "34:\tlearn: 0.8156226\ttotal: 6.26s\tremaining: 2m 52s\n",
      "35:\tlearn: 0.8137862\ttotal: 6.4s\tremaining: 2m 51s\n",
      "36:\tlearn: 0.8120437\ttotal: 6.55s\tremaining: 2m 50s\n",
      "37:\tlearn: 0.8100098\ttotal: 6.73s\tremaining: 2m 50s\n",
      "38:\tlearn: 0.8081509\ttotal: 6.87s\tremaining: 2m 49s\n",
      "39:\tlearn: 0.8060899\ttotal: 7.02s\tremaining: 2m 48s\n",
      "40:\tlearn: 0.8046291\ttotal: 7.19s\tremaining: 2m 48s\n",
      "41:\tlearn: 0.8029117\ttotal: 7.34s\tremaining: 2m 47s\n",
      "42:\tlearn: 0.8010879\ttotal: 7.49s\tremaining: 2m 46s\n",
      "43:\tlearn: 0.7991157\ttotal: 7.63s\tremaining: 2m 45s\n",
      "44:\tlearn: 0.7975632\ttotal: 7.78s\tremaining: 2m 45s\n",
      "45:\tlearn: 0.7962913\ttotal: 7.93s\tremaining: 2m 44s\n",
      "46:\tlearn: 0.7948041\ttotal: 8.09s\tremaining: 2m 44s\n",
      "47:\tlearn: 0.7932255\ttotal: 8.26s\tremaining: 2m 43s\n",
      "48:\tlearn: 0.7920342\ttotal: 8.4s\tremaining: 2m 43s\n",
      "49:\tlearn: 0.7908710\ttotal: 8.55s\tremaining: 2m 42s\n",
      "50:\tlearn: 0.7897110\ttotal: 8.72s\tremaining: 2m 42s\n",
      "51:\tlearn: 0.7885685\ttotal: 8.94s\tremaining: 2m 42s\n",
      "52:\tlearn: 0.7871565\ttotal: 9.22s\tremaining: 2m 44s\n",
      "53:\tlearn: 0.7858584\ttotal: 9.36s\tremaining: 2m 44s\n",
      "54:\tlearn: 0.7843019\ttotal: 9.53s\tremaining: 2m 43s\n",
      "55:\tlearn: 0.7833410\ttotal: 9.67s\tremaining: 2m 42s\n",
      "56:\tlearn: 0.7822957\ttotal: 9.89s\tremaining: 2m 43s\n",
      "57:\tlearn: 0.7811281\ttotal: 10.2s\tremaining: 2m 45s\n",
      "58:\tlearn: 0.7800118\ttotal: 10.3s\tremaining: 2m 44s\n",
      "59:\tlearn: 0.7787626\ttotal: 10.5s\tremaining: 2m 44s\n",
      "60:\tlearn: 0.7774168\ttotal: 10.7s\tremaining: 2m 44s\n",
      "61:\tlearn: 0.7762640\ttotal: 10.9s\tremaining: 2m 44s\n",
      "62:\tlearn: 0.7752568\ttotal: 11s\tremaining: 2m 44s\n",
      "63:\tlearn: 0.7742031\ttotal: 11.2s\tremaining: 2m 43s\n",
      "64:\tlearn: 0.7733291\ttotal: 11.4s\tremaining: 2m 43s\n",
      "65:\tlearn: 0.7724921\ttotal: 11.5s\tremaining: 2m 42s\n",
      "66:\tlearn: 0.7716784\ttotal: 11.7s\tremaining: 2m 42s\n",
      "67:\tlearn: 0.7707454\ttotal: 11.8s\tremaining: 2m 42s\n",
      "68:\tlearn: 0.7698958\ttotal: 12s\tremaining: 2m 42s\n",
      "69:\tlearn: 0.7689671\ttotal: 12.2s\tremaining: 2m 42s\n",
      "70:\tlearn: 0.7681592\ttotal: 12.4s\tremaining: 2m 42s\n",
      "71:\tlearn: 0.7672996\ttotal: 12.6s\tremaining: 2m 42s\n",
      "72:\tlearn: 0.7664308\ttotal: 12.8s\tremaining: 2m 42s\n",
      "73:\tlearn: 0.7656016\ttotal: 13.1s\tremaining: 2m 43s\n",
      "74:\tlearn: 0.7644665\ttotal: 13.3s\tremaining: 2m 43s\n",
      "75:\tlearn: 0.7637936\ttotal: 13.5s\tremaining: 2m 43s\n",
      "76:\tlearn: 0.7629367\ttotal: 13.7s\tremaining: 2m 43s\n",
      "77:\tlearn: 0.7620074\ttotal: 13.9s\tremaining: 2m 44s\n",
      "78:\tlearn: 0.7613046\ttotal: 14.1s\tremaining: 2m 44s\n",
      "79:\tlearn: 0.7605792\ttotal: 14.3s\tremaining: 2m 44s\n",
      "80:\tlearn: 0.7598767\ttotal: 14.6s\tremaining: 2m 45s\n",
      "81:\tlearn: 0.7592131\ttotal: 14.8s\tremaining: 2m 45s\n",
      "82:\tlearn: 0.7584003\ttotal: 15s\tremaining: 2m 45s\n",
      "83:\tlearn: 0.7577222\ttotal: 15.2s\tremaining: 2m 45s\n",
      "84:\tlearn: 0.7570589\ttotal: 15.4s\tremaining: 2m 45s\n",
      "85:\tlearn: 0.7562899\ttotal: 15.5s\tremaining: 2m 44s\n",
      "86:\tlearn: 0.7555095\ttotal: 15.7s\tremaining: 2m 44s\n",
      "87:\tlearn: 0.7545898\ttotal: 15.8s\tremaining: 2m 43s\n",
      "88:\tlearn: 0.7539846\ttotal: 16s\tremaining: 2m 43s\n",
      "89:\tlearn: 0.7531880\ttotal: 16.1s\tremaining: 2m 43s\n",
      "90:\tlearn: 0.7524868\ttotal: 16.3s\tremaining: 2m 42s\n",
      "91:\tlearn: 0.7519032\ttotal: 16.4s\tremaining: 2m 42s\n",
      "92:\tlearn: 0.7513213\ttotal: 16.6s\tremaining: 2m 42s\n",
      "93:\tlearn: 0.7506957\ttotal: 16.8s\tremaining: 2m 41s\n",
      "94:\tlearn: 0.7499856\ttotal: 16.9s\tremaining: 2m 41s\n",
      "95:\tlearn: 0.7494444\ttotal: 17.1s\tremaining: 2m 41s\n",
      "96:\tlearn: 0.7486558\ttotal: 17.3s\tremaining: 2m 40s\n",
      "97:\tlearn: 0.7479565\ttotal: 17.4s\tremaining: 2m 40s\n",
      "98:\tlearn: 0.7474654\ttotal: 17.6s\tremaining: 2m 40s\n",
      "99:\tlearn: 0.7469077\ttotal: 17.7s\tremaining: 2m 39s\n",
      "100:\tlearn: 0.7462977\ttotal: 17.9s\tremaining: 2m 39s\n",
      "101:\tlearn: 0.7457755\ttotal: 18s\tremaining: 2m 38s\n",
      "102:\tlearn: 0.7453368\ttotal: 18.2s\tremaining: 2m 38s\n",
      "103:\tlearn: 0.7446825\ttotal: 18.3s\tremaining: 2m 37s\n",
      "104:\tlearn: 0.7441772\ttotal: 18.5s\tremaining: 2m 37s\n",
      "105:\tlearn: 0.7437011\ttotal: 18.7s\tremaining: 2m 37s\n",
      "106:\tlearn: 0.7429158\ttotal: 18.8s\tremaining: 2m 37s\n",
      "107:\tlearn: 0.7423907\ttotal: 19s\tremaining: 2m 36s\n",
      "108:\tlearn: 0.7419185\ttotal: 19.1s\tremaining: 2m 36s\n",
      "109:\tlearn: 0.7414988\ttotal: 19.3s\tremaining: 2m 36s\n",
      "110:\tlearn: 0.7409677\ttotal: 19.5s\tremaining: 2m 36s\n",
      "111:\tlearn: 0.7404639\ttotal: 19.6s\tremaining: 2m 35s\n",
      "112:\tlearn: 0.7398607\ttotal: 19.8s\tremaining: 2m 35s\n",
      "113:\tlearn: 0.7392739\ttotal: 19.9s\tremaining: 2m 35s\n",
      "114:\tlearn: 0.7386621\ttotal: 20.1s\tremaining: 2m 34s\n",
      "115:\tlearn: 0.7381140\ttotal: 20.3s\tremaining: 2m 34s\n",
      "116:\tlearn: 0.7374258\ttotal: 20.4s\tremaining: 2m 33s\n",
      "117:\tlearn: 0.7369323\ttotal: 20.5s\tremaining: 2m 33s\n",
      "118:\tlearn: 0.7364558\ttotal: 20.7s\tremaining: 2m 33s\n",
      "119:\tlearn: 0.7359296\ttotal: 20.8s\tremaining: 2m 32s\n",
      "120:\tlearn: 0.7354805\ttotal: 20.9s\tremaining: 2m 32s\n",
      "121:\tlearn: 0.7348934\ttotal: 21.1s\tremaining: 2m 32s\n",
      "122:\tlearn: 0.7344410\ttotal: 21.3s\tremaining: 2m 31s\n",
      "123:\tlearn: 0.7338664\ttotal: 21.5s\tremaining: 2m 31s\n",
      "124:\tlearn: 0.7332548\ttotal: 21.6s\tremaining: 2m 31s\n",
      "125:\tlearn: 0.7328031\ttotal: 21.7s\tremaining: 2m 30s\n",
      "126:\tlearn: 0.7323269\ttotal: 21.9s\tremaining: 2m 30s\n",
      "127:\tlearn: 0.7319353\ttotal: 22.1s\tremaining: 2m 30s\n",
      "128:\tlearn: 0.7315820\ttotal: 22.2s\tremaining: 2m 29s\n",
      "129:\tlearn: 0.7311685\ttotal: 22.4s\tremaining: 2m 29s\n",
      "130:\tlearn: 0.7305898\ttotal: 22.6s\tremaining: 2m 29s\n",
      "131:\tlearn: 0.7302435\ttotal: 22.7s\tremaining: 2m 29s\n",
      "132:\tlearn: 0.7297430\ttotal: 22.8s\tremaining: 2m 28s\n",
      "133:\tlearn: 0.7293333\ttotal: 23s\tremaining: 2m 28s\n",
      "134:\tlearn: 0.7288203\ttotal: 23.1s\tremaining: 2m 28s\n",
      "135:\tlearn: 0.7284425\ttotal: 23.3s\tremaining: 2m 28s\n",
      "136:\tlearn: 0.7280310\ttotal: 23.5s\tremaining: 2m 27s\n",
      "137:\tlearn: 0.7275973\ttotal: 23.6s\tremaining: 2m 27s\n",
      "138:\tlearn: 0.7271808\ttotal: 23.7s\tremaining: 2m 27s\n",
      "139:\tlearn: 0.7267566\ttotal: 23.9s\tremaining: 2m 26s\n",
      "140:\tlearn: 0.7263347\ttotal: 24s\tremaining: 2m 26s\n",
      "141:\tlearn: 0.7259770\ttotal: 24.2s\tremaining: 2m 26s\n",
      "142:\tlearn: 0.7254933\ttotal: 24.3s\tremaining: 2m 25s\n",
      "143:\tlearn: 0.7250500\ttotal: 24.5s\tremaining: 2m 25s\n",
      "144:\tlearn: 0.7246645\ttotal: 24.6s\tremaining: 2m 25s\n",
      "145:\tlearn: 0.7242144\ttotal: 24.8s\tremaining: 2m 24s\n",
      "146:\tlearn: 0.7238243\ttotal: 24.9s\tremaining: 2m 24s\n",
      "147:\tlearn: 0.7233822\ttotal: 25.1s\tremaining: 2m 24s\n",
      "148:\tlearn: 0.7230452\ttotal: 25.2s\tremaining: 2m 24s\n",
      "149:\tlearn: 0.7226461\ttotal: 25.4s\tremaining: 2m 23s\n",
      "150:\tlearn: 0.7221835\ttotal: 25.6s\tremaining: 2m 23s\n",
      "151:\tlearn: 0.7218088\ttotal: 25.7s\tremaining: 2m 23s\n",
      "152:\tlearn: 0.7214480\ttotal: 25.9s\tremaining: 2m 23s\n",
      "153:\tlearn: 0.7211373\ttotal: 26.2s\tremaining: 2m 23s\n",
      "154:\tlearn: 0.7208642\ttotal: 26.4s\tremaining: 2m 23s\n",
      "155:\tlearn: 0.7205172\ttotal: 26.6s\tremaining: 2m 23s\n",
      "156:\tlearn: 0.7201681\ttotal: 26.8s\tremaining: 2m 23s\n",
      "157:\tlearn: 0.7196841\ttotal: 27s\tremaining: 2m 24s\n",
      "158:\tlearn: 0.7193790\ttotal: 27.2s\tremaining: 2m 24s\n",
      "159:\tlearn: 0.7189703\ttotal: 27.5s\tremaining: 2m 24s\n",
      "160:\tlearn: 0.7185315\ttotal: 27.7s\tremaining: 2m 24s\n",
      "161:\tlearn: 0.7181926\ttotal: 27.9s\tremaining: 2m 24s\n",
      "162:\tlearn: 0.7178477\ttotal: 28.2s\tremaining: 2m 24s\n",
      "163:\tlearn: 0.7174525\ttotal: 28.4s\tremaining: 2m 24s\n",
      "164:\tlearn: 0.7169824\ttotal: 28.6s\tremaining: 2m 24s\n",
      "165:\tlearn: 0.7166573\ttotal: 28.9s\tremaining: 2m 25s\n",
      "166:\tlearn: 0.7163029\ttotal: 29.1s\tremaining: 2m 25s\n",
      "167:\tlearn: 0.7158325\ttotal: 29.3s\tremaining: 2m 25s\n",
      "168:\tlearn: 0.7154556\ttotal: 29.5s\tremaining: 2m 25s\n",
      "169:\tlearn: 0.7151862\ttotal: 29.6s\tremaining: 2m 24s\n",
      "170:\tlearn: 0.7148374\ttotal: 29.8s\tremaining: 2m 24s\n",
      "171:\tlearn: 0.7145461\ttotal: 29.9s\tremaining: 2m 24s\n",
      "172:\tlearn: 0.7138883\ttotal: 30.1s\tremaining: 2m 24s\n",
      "173:\tlearn: 0.7135320\ttotal: 30.3s\tremaining: 2m 23s\n",
      "174:\tlearn: 0.7132420\ttotal: 30.4s\tremaining: 2m 23s\n",
      "175:\tlearn: 0.7127966\ttotal: 30.6s\tremaining: 2m 23s\n",
      "176:\tlearn: 0.7124754\ttotal: 30.7s\tremaining: 2m 22s\n",
      "177:\tlearn: 0.7121110\ttotal: 30.9s\tremaining: 2m 22s\n",
      "178:\tlearn: 0.7117869\ttotal: 31s\tremaining: 2m 22s\n",
      "179:\tlearn: 0.7114316\ttotal: 31.2s\tremaining: 2m 21s\n",
      "180:\tlearn: 0.7111331\ttotal: 31.3s\tremaining: 2m 21s\n",
      "181:\tlearn: 0.7108200\ttotal: 31.5s\tremaining: 2m 21s\n",
      "182:\tlearn: 0.7105197\ttotal: 31.6s\tremaining: 2m 21s\n",
      "183:\tlearn: 0.7101975\ttotal: 31.8s\tremaining: 2m 20s\n",
      "184:\tlearn: 0.7099321\ttotal: 31.9s\tremaining: 2m 20s\n",
      "185:\tlearn: 0.7095033\ttotal: 32s\tremaining: 2m 20s\n",
      "186:\tlearn: 0.7091968\ttotal: 32.2s\tremaining: 2m 19s\n",
      "187:\tlearn: 0.7087942\ttotal: 32.3s\tremaining: 2m 19s\n",
      "188:\tlearn: 0.7083885\ttotal: 32.5s\tremaining: 2m 19s\n",
      "189:\tlearn: 0.7079962\ttotal: 32.7s\tremaining: 2m 19s\n",
      "190:\tlearn: 0.7077366\ttotal: 32.8s\tremaining: 2m 19s\n",
      "191:\tlearn: 0.7075000\ttotal: 33s\tremaining: 2m 18s\n",
      "192:\tlearn: 0.7070690\ttotal: 33.1s\tremaining: 2m 18s\n",
      "193:\tlearn: 0.7067275\ttotal: 33.3s\tremaining: 2m 18s\n",
      "194:\tlearn: 0.7064926\ttotal: 33.4s\tremaining: 2m 17s\n",
      "195:\tlearn: 0.7061677\ttotal: 33.6s\tremaining: 2m 17s\n",
      "196:\tlearn: 0.7058939\ttotal: 33.7s\tremaining: 2m 17s\n",
      "197:\tlearn: 0.7056587\ttotal: 33.8s\tremaining: 2m 17s\n",
      "198:\tlearn: 0.7054436\ttotal: 34s\tremaining: 2m 16s\n",
      "199:\tlearn: 0.7050911\ttotal: 34.1s\tremaining: 2m 16s\n",
      "200:\tlearn: 0.7048662\ttotal: 34.3s\tremaining: 2m 16s\n",
      "201:\tlearn: 0.7045221\ttotal: 34.4s\tremaining: 2m 16s\n",
      "202:\tlearn: 0.7042554\ttotal: 34.6s\tremaining: 2m 15s\n",
      "203:\tlearn: 0.7039832\ttotal: 34.7s\tremaining: 2m 15s\n",
      "204:\tlearn: 0.7037128\ttotal: 34.9s\tremaining: 2m 15s\n",
      "205:\tlearn: 0.7034489\ttotal: 35s\tremaining: 2m 14s\n",
      "206:\tlearn: 0.7031694\ttotal: 35.2s\tremaining: 2m 14s\n",
      "207:\tlearn: 0.7028944\ttotal: 35.3s\tremaining: 2m 14s\n",
      "208:\tlearn: 0.7026280\ttotal: 35.5s\tremaining: 2m 14s\n",
      "209:\tlearn: 0.7023004\ttotal: 35.6s\tremaining: 2m 14s\n",
      "210:\tlearn: 0.7020622\ttotal: 35.8s\tremaining: 2m 13s\n",
      "211:\tlearn: 0.7017883\ttotal: 35.9s\tremaining: 2m 13s\n",
      "212:\tlearn: 0.7015337\ttotal: 36.1s\tremaining: 2m 13s\n",
      "213:\tlearn: 0.7012622\ttotal: 36.2s\tremaining: 2m 13s\n",
      "214:\tlearn: 0.7008902\ttotal: 36.4s\tremaining: 2m 12s\n",
      "215:\tlearn: 0.7006421\ttotal: 36.5s\tremaining: 2m 12s\n",
      "216:\tlearn: 0.7003212\ttotal: 36.7s\tremaining: 2m 12s\n",
      "217:\tlearn: 0.7001459\ttotal: 36.8s\tremaining: 2m 12s\n",
      "218:\tlearn: 0.6998862\ttotal: 37s\tremaining: 2m 11s\n",
      "219:\tlearn: 0.6996188\ttotal: 37.1s\tremaining: 2m 11s\n",
      "220:\tlearn: 0.6994090\ttotal: 37.3s\tremaining: 2m 11s\n",
      "221:\tlearn: 0.6990811\ttotal: 37.5s\tremaining: 2m 11s\n",
      "222:\tlearn: 0.6987914\ttotal: 37.6s\tremaining: 2m 11s\n",
      "223:\tlearn: 0.6984939\ttotal: 37.8s\tremaining: 2m 10s\n",
      "224:\tlearn: 0.6981351\ttotal: 37.9s\tremaining: 2m 10s\n",
      "225:\tlearn: 0.6979492\ttotal: 38.1s\tremaining: 2m 10s\n",
      "226:\tlearn: 0.6975887\ttotal: 38.2s\tremaining: 2m 10s\n",
      "227:\tlearn: 0.6973832\ttotal: 38.4s\tremaining: 2m 9s\n",
      "228:\tlearn: 0.6970085\ttotal: 38.5s\tremaining: 2m 9s\n",
      "229:\tlearn: 0.6966907\ttotal: 38.7s\tremaining: 2m 9s\n",
      "230:\tlearn: 0.6964428\ttotal: 38.8s\tremaining: 2m 9s\n",
      "231:\tlearn: 0.6962173\ttotal: 39s\tremaining: 2m 9s\n",
      "232:\tlearn: 0.6960048\ttotal: 39.2s\tremaining: 2m 8s\n",
      "233:\tlearn: 0.6957673\ttotal: 39.3s\tremaining: 2m 8s\n",
      "234:\tlearn: 0.6955127\ttotal: 39.5s\tremaining: 2m 8s\n",
      "235:\tlearn: 0.6949470\ttotal: 39.7s\tremaining: 2m 8s\n",
      "236:\tlearn: 0.6946890\ttotal: 39.9s\tremaining: 2m 8s\n",
      "237:\tlearn: 0.6944876\ttotal: 40.1s\tremaining: 2m 8s\n",
      "238:\tlearn: 0.6942752\ttotal: 40.3s\tremaining: 2m 8s\n",
      "239:\tlearn: 0.6940357\ttotal: 40.6s\tremaining: 2m 8s\n",
      "240:\tlearn: 0.6938368\ttotal: 40.8s\tremaining: 2m 8s\n",
      "241:\tlearn: 0.6935770\ttotal: 41.1s\tremaining: 2m 8s\n",
      "242:\tlearn: 0.6933432\ttotal: 41.5s\tremaining: 2m 9s\n",
      "243:\tlearn: 0.6930958\ttotal: 41.8s\tremaining: 2m 9s\n",
      "244:\tlearn: 0.6928376\ttotal: 41.9s\tremaining: 2m 9s\n",
      "245:\tlearn: 0.6925707\ttotal: 42.2s\tremaining: 2m 9s\n",
      "246:\tlearn: 0.6923573\ttotal: 42.4s\tremaining: 2m 9s\n",
      "247:\tlearn: 0.6921012\ttotal: 42.6s\tremaining: 2m 9s\n",
      "248:\tlearn: 0.6918144\ttotal: 42.8s\tremaining: 2m 9s\n",
      "249:\tlearn: 0.6915775\ttotal: 43s\tremaining: 2m 9s\n",
      "250:\tlearn: 0.6913363\ttotal: 43.2s\tremaining: 2m 8s\n",
      "251:\tlearn: 0.6911272\ttotal: 43.3s\tremaining: 2m 8s\n",
      "252:\tlearn: 0.6909201\ttotal: 43.5s\tremaining: 2m 8s\n",
      "253:\tlearn: 0.6907577\ttotal: 43.6s\tremaining: 2m 8s\n",
      "254:\tlearn: 0.6905473\ttotal: 43.7s\tremaining: 2m 7s\n",
      "255:\tlearn: 0.6903393\ttotal: 43.9s\tremaining: 2m 7s\n",
      "256:\tlearn: 0.6901347\ttotal: 44.1s\tremaining: 2m 7s\n",
      "257:\tlearn: 0.6898392\ttotal: 44.2s\tremaining: 2m 7s\n",
      "258:\tlearn: 0.6896248\ttotal: 44.3s\tremaining: 2m 6s\n",
      "259:\tlearn: 0.6894372\ttotal: 44.5s\tremaining: 2m 6s\n",
      "260:\tlearn: 0.6891807\ttotal: 44.6s\tremaining: 2m 6s\n",
      "261:\tlearn: 0.6889344\ttotal: 44.8s\tremaining: 2m 6s\n",
      "262:\tlearn: 0.6887453\ttotal: 44.9s\tremaining: 2m 5s\n",
      "263:\tlearn: 0.6885577\ttotal: 45.1s\tremaining: 2m 5s\n",
      "264:\tlearn: 0.6881689\ttotal: 45.2s\tremaining: 2m 5s\n",
      "265:\tlearn: 0.6879199\ttotal: 45.4s\tremaining: 2m 5s\n",
      "266:\tlearn: 0.6876511\ttotal: 45.5s\tremaining: 2m 5s\n",
      "267:\tlearn: 0.6874321\ttotal: 45.7s\tremaining: 2m 4s\n",
      "268:\tlearn: 0.6872605\ttotal: 45.8s\tremaining: 2m 4s\n",
      "269:\tlearn: 0.6870953\ttotal: 46s\tremaining: 2m 4s\n",
      "270:\tlearn: 0.6867655\ttotal: 46.1s\tremaining: 2m 4s\n",
      "271:\tlearn: 0.6865636\ttotal: 46.3s\tremaining: 2m 3s\n",
      "272:\tlearn: 0.6863013\ttotal: 46.4s\tremaining: 2m 3s\n",
      "273:\tlearn: 0.6860713\ttotal: 46.6s\tremaining: 2m 3s\n",
      "274:\tlearn: 0.6858980\ttotal: 46.8s\tremaining: 2m 3s\n",
      "275:\tlearn: 0.6856657\ttotal: 46.9s\tremaining: 2m 3s\n",
      "276:\tlearn: 0.6854080\ttotal: 47.1s\tremaining: 2m 2s\n",
      "277:\tlearn: 0.6851895\ttotal: 47.2s\tremaining: 2m 2s\n",
      "278:\tlearn: 0.6848913\ttotal: 47.4s\tremaining: 2m 2s\n",
      "279:\tlearn: 0.6847195\ttotal: 47.5s\tremaining: 2m 2s\n",
      "280:\tlearn: 0.6845148\ttotal: 47.7s\tremaining: 2m 1s\n",
      "281:\tlearn: 0.6842764\ttotal: 47.8s\tremaining: 2m 1s\n",
      "282:\tlearn: 0.6840466\ttotal: 48s\tremaining: 2m 1s\n",
      "283:\tlearn: 0.6837907\ttotal: 48.1s\tremaining: 2m 1s\n",
      "284:\tlearn: 0.6835725\ttotal: 48.3s\tremaining: 2m 1s\n",
      "285:\tlearn: 0.6833592\ttotal: 48.4s\tremaining: 2m\n",
      "286:\tlearn: 0.6831450\ttotal: 48.6s\tremaining: 2m\n",
      "287:\tlearn: 0.6829578\ttotal: 48.7s\tremaining: 2m\n",
      "288:\tlearn: 0.6827951\ttotal: 48.9s\tremaining: 2m\n",
      "289:\tlearn: 0.6825517\ttotal: 49s\tremaining: 1m 59s\n",
      "290:\tlearn: 0.6823622\ttotal: 49.2s\tremaining: 1m 59s\n",
      "291:\tlearn: 0.6822309\ttotal: 49.3s\tremaining: 1m 59s\n",
      "292:\tlearn: 0.6820432\ttotal: 49.4s\tremaining: 1m 59s\n",
      "293:\tlearn: 0.6818809\ttotal: 49.6s\tremaining: 1m 59s\n",
      "294:\tlearn: 0.6817545\ttotal: 49.7s\tremaining: 1m 58s\n",
      "295:\tlearn: 0.6814156\ttotal: 49.8s\tremaining: 1m 58s\n",
      "296:\tlearn: 0.6812116\ttotal: 50s\tremaining: 1m 58s\n",
      "297:\tlearn: 0.6809737\ttotal: 50.1s\tremaining: 1m 58s\n",
      "298:\tlearn: 0.6807371\ttotal: 50.2s\tremaining: 1m 57s\n",
      "299:\tlearn: 0.6805572\ttotal: 50.4s\tremaining: 1m 57s\n",
      "300:\tlearn: 0.6802918\ttotal: 50.5s\tremaining: 1m 57s\n",
      "301:\tlearn: 0.6801556\ttotal: 50.6s\tremaining: 1m 57s\n",
      "302:\tlearn: 0.6799617\ttotal: 50.8s\tremaining: 1m 56s\n",
      "303:\tlearn: 0.6797519\ttotal: 50.9s\tremaining: 1m 56s\n",
      "304:\tlearn: 0.6795677\ttotal: 51.1s\tremaining: 1m 56s\n",
      "305:\tlearn: 0.6793784\ttotal: 51.2s\tremaining: 1m 56s\n",
      "306:\tlearn: 0.6791883\ttotal: 51.4s\tremaining: 1m 55s\n",
      "307:\tlearn: 0.6789579\ttotal: 51.5s\tremaining: 1m 55s\n",
      "308:\tlearn: 0.6787833\ttotal: 51.7s\tremaining: 1m 55s\n",
      "309:\tlearn: 0.6786145\ttotal: 51.8s\tremaining: 1m 55s\n",
      "310:\tlearn: 0.6783104\ttotal: 52s\tremaining: 1m 55s\n",
      "311:\tlearn: 0.6780288\ttotal: 52.1s\tremaining: 1m 54s\n",
      "312:\tlearn: 0.6777863\ttotal: 52.3s\tremaining: 1m 54s\n",
      "313:\tlearn: 0.6775960\ttotal: 52.4s\tremaining: 1m 54s\n",
      "314:\tlearn: 0.6773927\ttotal: 52.6s\tremaining: 1m 54s\n",
      "315:\tlearn: 0.6771358\ttotal: 52.7s\tremaining: 1m 54s\n",
      "316:\tlearn: 0.6769736\ttotal: 52.9s\tremaining: 1m 53s\n",
      "317:\tlearn: 0.6767539\ttotal: 53s\tremaining: 1m 53s\n",
      "318:\tlearn: 0.6765263\ttotal: 53.1s\tremaining: 1m 53s\n",
      "319:\tlearn: 0.6763695\ttotal: 53.3s\tremaining: 1m 53s\n",
      "320:\tlearn: 0.6762260\ttotal: 53.6s\tremaining: 1m 53s\n",
      "321:\tlearn: 0.6760540\ttotal: 53.8s\tremaining: 1m 53s\n",
      "322:\tlearn: 0.6758166\ttotal: 54s\tremaining: 1m 53s\n",
      "323:\tlearn: 0.6756454\ttotal: 54.2s\tremaining: 1m 53s\n",
      "324:\tlearn: 0.6754979\ttotal: 54.4s\tremaining: 1m 52s\n",
      "325:\tlearn: 0.6753127\ttotal: 54.6s\tremaining: 1m 52s\n",
      "326:\tlearn: 0.6751453\ttotal: 54.8s\tremaining: 1m 52s\n",
      "327:\tlearn: 0.6749897\ttotal: 55s\tremaining: 1m 52s\n",
      "328:\tlearn: 0.6748547\ttotal: 55.2s\tremaining: 1m 52s\n",
      "329:\tlearn: 0.6746629\ttotal: 55.4s\tremaining: 1m 52s\n",
      "330:\tlearn: 0.6744953\ttotal: 55.6s\tremaining: 1m 52s\n",
      "331:\tlearn: 0.6742823\ttotal: 55.8s\tremaining: 1m 52s\n",
      "332:\tlearn: 0.6741202\ttotal: 56s\tremaining: 1m 52s\n",
      "333:\tlearn: 0.6739364\ttotal: 56.2s\tremaining: 1m 52s\n",
      "334:\tlearn: 0.6737249\ttotal: 56.4s\tremaining: 1m 52s\n",
      "335:\tlearn: 0.6734651\ttotal: 56.6s\tremaining: 1m 51s\n",
      "336:\tlearn: 0.6733191\ttotal: 56.8s\tremaining: 1m 51s\n",
      "337:\tlearn: 0.6731457\ttotal: 57s\tremaining: 1m 51s\n",
      "338:\tlearn: 0.6729685\ttotal: 57.1s\tremaining: 1m 51s\n",
      "339:\tlearn: 0.6727796\ttotal: 57.3s\tremaining: 1m 51s\n",
      "340:\tlearn: 0.6726228\ttotal: 57.4s\tremaining: 1m 50s\n",
      "341:\tlearn: 0.6724402\ttotal: 57.6s\tremaining: 1m 50s\n",
      "342:\tlearn: 0.6723129\ttotal: 57.7s\tremaining: 1m 50s\n",
      "343:\tlearn: 0.6721720\ttotal: 57.8s\tremaining: 1m 50s\n",
      "344:\tlearn: 0.6718345\ttotal: 58s\tremaining: 1m 50s\n",
      "345:\tlearn: 0.6717074\ttotal: 58.1s\tremaining: 1m 49s\n",
      "346:\tlearn: 0.6715713\ttotal: 58.2s\tremaining: 1m 49s\n",
      "347:\tlearn: 0.6714073\ttotal: 58.4s\tremaining: 1m 49s\n",
      "348:\tlearn: 0.6712345\ttotal: 58.5s\tremaining: 1m 49s\n",
      "349:\tlearn: 0.6710754\ttotal: 58.7s\tremaining: 1m 48s\n",
      "350:\tlearn: 0.6709247\ttotal: 58.8s\tremaining: 1m 48s\n",
      "351:\tlearn: 0.6706671\ttotal: 59s\tremaining: 1m 48s\n",
      "352:\tlearn: 0.6705029\ttotal: 59.1s\tremaining: 1m 48s\n",
      "353:\tlearn: 0.6703318\ttotal: 59.2s\tremaining: 1m 48s\n",
      "354:\tlearn: 0.6701772\ttotal: 59.4s\tremaining: 1m 47s\n",
      "355:\tlearn: 0.6700568\ttotal: 59.5s\tremaining: 1m 47s\n",
      "356:\tlearn: 0.6699014\ttotal: 59.7s\tremaining: 1m 47s\n",
      "357:\tlearn: 0.6696943\ttotal: 59.8s\tremaining: 1m 47s\n",
      "358:\tlearn: 0.6695527\ttotal: 60s\tremaining: 1m 47s\n",
      "359:\tlearn: 0.6694221\ttotal: 1m\tremaining: 1m 46s\n",
      "360:\tlearn: 0.6692786\ttotal: 1m\tremaining: 1m 46s\n",
      "361:\tlearn: 0.6691398\ttotal: 1m\tremaining: 1m 46s\n",
      "362:\tlearn: 0.6689866\ttotal: 1m\tremaining: 1m 46s\n",
      "363:\tlearn: 0.6687541\ttotal: 1m\tremaining: 1m 45s\n",
      "364:\tlearn: 0.6686205\ttotal: 1m\tremaining: 1m 45s\n",
      "365:\tlearn: 0.6684199\ttotal: 1m\tremaining: 1m 45s\n",
      "366:\tlearn: 0.6683094\ttotal: 1m 1s\tremaining: 1m 45s\n",
      "367:\tlearn: 0.6681368\ttotal: 1m 1s\tremaining: 1m 45s\n",
      "368:\tlearn: 0.6679826\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "369:\tlearn: 0.6677879\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "370:\tlearn: 0.6676485\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "371:\tlearn: 0.6674735\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "372:\tlearn: 0.6673359\ttotal: 1m 1s\tremaining: 1m 44s\n",
      "373:\tlearn: 0.6671607\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "374:\tlearn: 0.6669930\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "375:\tlearn: 0.6667985\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "376:\tlearn: 0.6666261\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "377:\tlearn: 0.6664603\ttotal: 1m 2s\tremaining: 1m 43s\n",
      "378:\tlearn: 0.6662735\ttotal: 1m 2s\tremaining: 1m 42s\n",
      "379:\tlearn: 0.6660743\ttotal: 1m 2s\tremaining: 1m 42s\n",
      "380:\tlearn: 0.6658737\ttotal: 1m 3s\tremaining: 1m 42s\n",
      "381:\tlearn: 0.6657033\ttotal: 1m 3s\tremaining: 1m 42s\n",
      "382:\tlearn: 0.6655467\ttotal: 1m 3s\tremaining: 1m 42s\n",
      "383:\tlearn: 0.6653944\ttotal: 1m 3s\tremaining: 1m 41s\n",
      "384:\tlearn: 0.6652480\ttotal: 1m 3s\tremaining: 1m 41s\n",
      "385:\tlearn: 0.6650546\ttotal: 1m 3s\tremaining: 1m 41s\n",
      "386:\tlearn: 0.6648720\ttotal: 1m 3s\tremaining: 1m 41s\n",
      "387:\tlearn: 0.6647281\ttotal: 1m 4s\tremaining: 1m 41s\n",
      "388:\tlearn: 0.6645760\ttotal: 1m 4s\tremaining: 1m 40s\n",
      "389:\tlearn: 0.6643915\ttotal: 1m 4s\tremaining: 1m 40s\n",
      "390:\tlearn: 0.6642433\ttotal: 1m 4s\tremaining: 1m 40s\n",
      "391:\tlearn: 0.6640759\ttotal: 1m 4s\tremaining: 1m 40s\n",
      "392:\tlearn: 0.6639563\ttotal: 1m 4s\tremaining: 1m 40s\n",
      "393:\tlearn: 0.6638410\ttotal: 1m 4s\tremaining: 1m 39s\n",
      "394:\tlearn: 0.6636436\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "395:\tlearn: 0.6635121\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "396:\tlearn: 0.6633592\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "397:\tlearn: 0.6630484\ttotal: 1m 5s\tremaining: 1m 39s\n",
      "398:\tlearn: 0.6628966\ttotal: 1m 5s\tremaining: 1m 38s\n",
      "399:\tlearn: 0.6627000\ttotal: 1m 5s\tremaining: 1m 38s\n",
      "400:\tlearn: 0.6625089\ttotal: 1m 5s\tremaining: 1m 38s\n",
      "401:\tlearn: 0.6624050\ttotal: 1m 6s\tremaining: 1m 38s\n",
      "402:\tlearn: 0.6622599\ttotal: 1m 6s\tremaining: 1m 38s\n",
      "403:\tlearn: 0.6621175\ttotal: 1m 6s\tremaining: 1m 37s\n",
      "404:\tlearn: 0.6619794\ttotal: 1m 6s\tremaining: 1m 37s\n",
      "405:\tlearn: 0.6618648\ttotal: 1m 6s\tremaining: 1m 37s\n",
      "406:\tlearn: 0.6617134\ttotal: 1m 6s\tremaining: 1m 37s\n",
      "407:\tlearn: 0.6614872\ttotal: 1m 6s\tremaining: 1m 37s\n",
      "408:\tlearn: 0.6613995\ttotal: 1m 7s\tremaining: 1m 36s\n",
      "409:\tlearn: 0.6611808\ttotal: 1m 7s\tremaining: 1m 36s\n",
      "410:\tlearn: 0.6610322\ttotal: 1m 7s\tremaining: 1m 36s\n",
      "411:\tlearn: 0.6609291\ttotal: 1m 7s\tremaining: 1m 36s\n",
      "412:\tlearn: 0.6607766\ttotal: 1m 7s\tremaining: 1m 36s\n",
      "413:\tlearn: 0.6606393\ttotal: 1m 7s\tremaining: 1m 36s\n",
      "414:\tlearn: 0.6605041\ttotal: 1m 8s\tremaining: 1m 36s\n",
      "415:\tlearn: 0.6603516\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "416:\tlearn: 0.6602032\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "417:\tlearn: 0.6600606\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "418:\tlearn: 0.6599137\ttotal: 1m 8s\tremaining: 1m 35s\n",
      "419:\tlearn: 0.6597517\ttotal: 1m 9s\tremaining: 1m 35s\n",
      "420:\tlearn: 0.6596036\ttotal: 1m 9s\tremaining: 1m 35s\n",
      "421:\tlearn: 0.6594657\ttotal: 1m 9s\tremaining: 1m 35s\n",
      "422:\tlearn: 0.6592856\ttotal: 1m 9s\tremaining: 1m 35s\n",
      "423:\tlearn: 0.6591215\ttotal: 1m 10s\tremaining: 1m 35s\n",
      "424:\tlearn: 0.6589666\ttotal: 1m 10s\tremaining: 1m 35s\n",
      "425:\tlearn: 0.6588333\ttotal: 1m 10s\tremaining: 1m 34s\n",
      "426:\tlearn: 0.6586938\ttotal: 1m 10s\tremaining: 1m 34s\n",
      "427:\tlearn: 0.6585587\ttotal: 1m 10s\tremaining: 1m 34s\n",
      "428:\tlearn: 0.6583972\ttotal: 1m 10s\tremaining: 1m 34s\n",
      "429:\tlearn: 0.6582089\ttotal: 1m 11s\tremaining: 1m 34s\n",
      "430:\tlearn: 0.6580755\ttotal: 1m 11s\tremaining: 1m 33s\n",
      "431:\tlearn: 0.6578396\ttotal: 1m 11s\tremaining: 1m 33s\n",
      "432:\tlearn: 0.6577368\ttotal: 1m 11s\tremaining: 1m 33s\n",
      "433:\tlearn: 0.6575892\ttotal: 1m 11s\tremaining: 1m 33s\n",
      "434:\tlearn: 0.6574704\ttotal: 1m 11s\tremaining: 1m 33s\n",
      "435:\tlearn: 0.6573385\ttotal: 1m 11s\tremaining: 1m 32s\n",
      "436:\tlearn: 0.6571970\ttotal: 1m 11s\tremaining: 1m 32s\n",
      "437:\tlearn: 0.6570308\ttotal: 1m 12s\tremaining: 1m 32s\n",
      "438:\tlearn: 0.6569459\ttotal: 1m 12s\tremaining: 1m 32s\n",
      "439:\tlearn: 0.6568070\ttotal: 1m 12s\tremaining: 1m 32s\n",
      "440:\tlearn: 0.6566592\ttotal: 1m 12s\tremaining: 1m 31s\n",
      "441:\tlearn: 0.6565476\ttotal: 1m 12s\tremaining: 1m 31s\n",
      "442:\tlearn: 0.6564076\ttotal: 1m 12s\tremaining: 1m 31s\n",
      "443:\tlearn: 0.6562313\ttotal: 1m 12s\tremaining: 1m 31s\n",
      "444:\tlearn: 0.6560743\ttotal: 1m 13s\tremaining: 1m 31s\n",
      "445:\tlearn: 0.6559263\ttotal: 1m 13s\tremaining: 1m 30s\n",
      "446:\tlearn: 0.6558142\ttotal: 1m 13s\tremaining: 1m 30s\n",
      "447:\tlearn: 0.6556855\ttotal: 1m 13s\tremaining: 1m 30s\n",
      "448:\tlearn: 0.6555395\ttotal: 1m 13s\tremaining: 1m 30s\n",
      "449:\tlearn: 0.6554107\ttotal: 1m 13s\tremaining: 1m 30s\n",
      "450:\tlearn: 0.6553307\ttotal: 1m 13s\tremaining: 1m 29s\n",
      "451:\tlearn: 0.6551355\ttotal: 1m 14s\tremaining: 1m 29s\n",
      "452:\tlearn: 0.6549707\ttotal: 1m 14s\tremaining: 1m 29s\n",
      "453:\tlearn: 0.6548444\ttotal: 1m 14s\tremaining: 1m 29s\n",
      "454:\tlearn: 0.6547314\ttotal: 1m 14s\tremaining: 1m 29s\n",
      "455:\tlearn: 0.6545837\ttotal: 1m 14s\tremaining: 1m 29s\n",
      "456:\tlearn: 0.6544142\ttotal: 1m 14s\tremaining: 1m 28s\n",
      "457:\tlearn: 0.6542328\ttotal: 1m 14s\tremaining: 1m 28s\n",
      "458:\tlearn: 0.6541401\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "459:\tlearn: 0.6539965\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "460:\tlearn: 0.6539006\ttotal: 1m 15s\tremaining: 1m 28s\n",
      "461:\tlearn: 0.6536562\ttotal: 1m 15s\tremaining: 1m 27s\n",
      "462:\tlearn: 0.6535409\ttotal: 1m 15s\tremaining: 1m 27s\n",
      "463:\tlearn: 0.6534028\ttotal: 1m 15s\tremaining: 1m 27s\n",
      "464:\tlearn: 0.6532101\ttotal: 1m 15s\tremaining: 1m 27s\n",
      "465:\tlearn: 0.6530134\ttotal: 1m 16s\tremaining: 1m 27s\n",
      "466:\tlearn: 0.6528921\ttotal: 1m 16s\tremaining: 1m 27s\n",
      "467:\tlearn: 0.6527439\ttotal: 1m 16s\tremaining: 1m 26s\n",
      "468:\tlearn: 0.6525973\ttotal: 1m 16s\tremaining: 1m 26s\n",
      "469:\tlearn: 0.6525136\ttotal: 1m 16s\tremaining: 1m 26s\n",
      "470:\tlearn: 0.6523257\ttotal: 1m 16s\tremaining: 1m 26s\n",
      "471:\tlearn: 0.6521998\ttotal: 1m 16s\tremaining: 1m 26s\n",
      "472:\tlearn: 0.6520730\ttotal: 1m 17s\tremaining: 1m 25s\n",
      "473:\tlearn: 0.6519698\ttotal: 1m 17s\tremaining: 1m 25s\n",
      "474:\tlearn: 0.6517449\ttotal: 1m 17s\tremaining: 1m 25s\n",
      "475:\tlearn: 0.6515967\ttotal: 1m 17s\tremaining: 1m 25s\n",
      "476:\tlearn: 0.6514908\ttotal: 1m 17s\tremaining: 1m 25s\n",
      "477:\tlearn: 0.6513800\ttotal: 1m 17s\tremaining: 1m 24s\n",
      "478:\tlearn: 0.6512488\ttotal: 1m 17s\tremaining: 1m 24s\n",
      "479:\tlearn: 0.6511724\ttotal: 1m 18s\tremaining: 1m 24s\n",
      "480:\tlearn: 0.6510075\ttotal: 1m 18s\tremaining: 1m 24s\n",
      "481:\tlearn: 0.6509089\ttotal: 1m 18s\tremaining: 1m 24s\n",
      "482:\tlearn: 0.6506645\ttotal: 1m 18s\tremaining: 1m 23s\n",
      "483:\tlearn: 0.6505590\ttotal: 1m 18s\tremaining: 1m 23s\n",
      "484:\tlearn: 0.6503870\ttotal: 1m 18s\tremaining: 1m 23s\n",
      "485:\tlearn: 0.6501885\ttotal: 1m 18s\tremaining: 1m 23s\n",
      "486:\tlearn: 0.6500843\ttotal: 1m 19s\tremaining: 1m 23s\n",
      "487:\tlearn: 0.6499205\ttotal: 1m 19s\tremaining: 1m 23s\n",
      "488:\tlearn: 0.6497985\ttotal: 1m 19s\tremaining: 1m 22s\n",
      "489:\tlearn: 0.6496579\ttotal: 1m 19s\tremaining: 1m 22s\n",
      "490:\tlearn: 0.6495511\ttotal: 1m 19s\tremaining: 1m 22s\n",
      "491:\tlearn: 0.6494562\ttotal: 1m 19s\tremaining: 1m 22s\n",
      "492:\tlearn: 0.6493678\ttotal: 1m 19s\tremaining: 1m 22s\n",
      "493:\tlearn: 0.6492565\ttotal: 1m 19s\tremaining: 1m 21s\n",
      "494:\tlearn: 0.6489736\ttotal: 1m 20s\tremaining: 1m 21s\n",
      "495:\tlearn: 0.6488598\ttotal: 1m 20s\tremaining: 1m 21s\n",
      "496:\tlearn: 0.6487305\ttotal: 1m 20s\tremaining: 1m 21s\n",
      "497:\tlearn: 0.6485997\ttotal: 1m 20s\tremaining: 1m 21s\n",
      "498:\tlearn: 0.6484837\ttotal: 1m 20s\tremaining: 1m 21s\n",
      "499:\tlearn: 0.6483512\ttotal: 1m 20s\tremaining: 1m 20s\n",
      "500:\tlearn: 0.6482279\ttotal: 1m 21s\tremaining: 1m 20s\n",
      "501:\tlearn: 0.6480697\ttotal: 1m 21s\tremaining: 1m 20s\n",
      "502:\tlearn: 0.6479363\ttotal: 1m 21s\tremaining: 1m 20s\n",
      "503:\tlearn: 0.6477511\ttotal: 1m 21s\tremaining: 1m 20s\n",
      "504:\tlearn: 0.6476698\ttotal: 1m 21s\tremaining: 1m 20s\n",
      "505:\tlearn: 0.6475517\ttotal: 1m 22s\tremaining: 1m 20s\n",
      "506:\tlearn: 0.6474557\ttotal: 1m 22s\tremaining: 1m 20s\n",
      "507:\tlearn: 0.6473772\ttotal: 1m 22s\tremaining: 1m 19s\n",
      "508:\tlearn: 0.6472691\ttotal: 1m 22s\tremaining: 1m 19s\n",
      "509:\tlearn: 0.6471658\ttotal: 1m 22s\tremaining: 1m 19s\n",
      "510:\tlearn: 0.6470764\ttotal: 1m 23s\tremaining: 1m 19s\n",
      "511:\tlearn: 0.6469192\ttotal: 1m 23s\tremaining: 1m 19s\n",
      "512:\tlearn: 0.6467851\ttotal: 1m 23s\tremaining: 1m 19s\n",
      "513:\tlearn: 0.6466290\ttotal: 1m 23s\tremaining: 1m 19s\n",
      "514:\tlearn: 0.6465248\ttotal: 1m 23s\tremaining: 1m 19s\n",
      "515:\tlearn: 0.6464483\ttotal: 1m 24s\tremaining: 1m 18s\n",
      "516:\tlearn: 0.6463112\ttotal: 1m 24s\tremaining: 1m 18s\n",
      "517:\tlearn: 0.6462129\ttotal: 1m 24s\tremaining: 1m 18s\n",
      "518:\tlearn: 0.6461221\ttotal: 1m 24s\tremaining: 1m 18s\n",
      "519:\tlearn: 0.6459512\ttotal: 1m 24s\tremaining: 1m 18s\n",
      "520:\tlearn: 0.6458460\ttotal: 1m 24s\tremaining: 1m 17s\n",
      "521:\tlearn: 0.6457099\ttotal: 1m 24s\tremaining: 1m 17s\n",
      "522:\tlearn: 0.6456207\ttotal: 1m 25s\tremaining: 1m 17s\n",
      "523:\tlearn: 0.6455299\ttotal: 1m 25s\tremaining: 1m 17s\n",
      "524:\tlearn: 0.6454210\ttotal: 1m 25s\tremaining: 1m 17s\n",
      "525:\tlearn: 0.6452396\ttotal: 1m 25s\tremaining: 1m 17s\n",
      "526:\tlearn: 0.6451342\ttotal: 1m 25s\tremaining: 1m 16s\n",
      "527:\tlearn: 0.6450504\ttotal: 1m 25s\tremaining: 1m 16s\n",
      "528:\tlearn: 0.6448665\ttotal: 1m 25s\tremaining: 1m 16s\n",
      "529:\tlearn: 0.6447517\ttotal: 1m 26s\tremaining: 1m 16s\n",
      "530:\tlearn: 0.6446373\ttotal: 1m 26s\tremaining: 1m 16s\n",
      "531:\tlearn: 0.6445408\ttotal: 1m 26s\tremaining: 1m 15s\n",
      "532:\tlearn: 0.6444066\ttotal: 1m 26s\tremaining: 1m 15s\n",
      "533:\tlearn: 0.6442662\ttotal: 1m 26s\tremaining: 1m 15s\n",
      "534:\tlearn: 0.6441597\ttotal: 1m 26s\tremaining: 1m 15s\n",
      "535:\tlearn: 0.6440465\ttotal: 1m 26s\tremaining: 1m 15s\n",
      "536:\tlearn: 0.6439203\ttotal: 1m 27s\tremaining: 1m 15s\n",
      "537:\tlearn: 0.6437500\ttotal: 1m 27s\tremaining: 1m 14s\n",
      "538:\tlearn: 0.6436559\ttotal: 1m 27s\tremaining: 1m 14s\n",
      "539:\tlearn: 0.6435230\ttotal: 1m 27s\tremaining: 1m 14s\n",
      "540:\tlearn: 0.6433824\ttotal: 1m 27s\tremaining: 1m 14s\n",
      "541:\tlearn: 0.6432177\ttotal: 1m 27s\tremaining: 1m 14s\n",
      "542:\tlearn: 0.6430871\ttotal: 1m 27s\tremaining: 1m 13s\n",
      "543:\tlearn: 0.6429293\ttotal: 1m 28s\tremaining: 1m 13s\n",
      "544:\tlearn: 0.6427758\ttotal: 1m 28s\tremaining: 1m 13s\n",
      "545:\tlearn: 0.6426474\ttotal: 1m 28s\tremaining: 1m 13s\n",
      "546:\tlearn: 0.6424690\ttotal: 1m 28s\tremaining: 1m 13s\n",
      "547:\tlearn: 0.6423436\ttotal: 1m 28s\tremaining: 1m 13s\n",
      "548:\tlearn: 0.6422503\ttotal: 1m 28s\tremaining: 1m 12s\n",
      "549:\tlearn: 0.6421556\ttotal: 1m 28s\tremaining: 1m 12s\n",
      "550:\tlearn: 0.6419589\ttotal: 1m 29s\tremaining: 1m 12s\n",
      "551:\tlearn: 0.6417957\ttotal: 1m 29s\tremaining: 1m 12s\n",
      "552:\tlearn: 0.6417073\ttotal: 1m 29s\tremaining: 1m 12s\n",
      "553:\tlearn: 0.6415772\ttotal: 1m 29s\tremaining: 1m 12s\n",
      "554:\tlearn: 0.6414211\ttotal: 1m 29s\tremaining: 1m 11s\n",
      "555:\tlearn: 0.6412885\ttotal: 1m 29s\tremaining: 1m 11s\n",
      "556:\tlearn: 0.6411404\ttotal: 1m 29s\tremaining: 1m 11s\n",
      "557:\tlearn: 0.6409284\ttotal: 1m 30s\tremaining: 1m 11s\n",
      "558:\tlearn: 0.6406841\ttotal: 1m 30s\tremaining: 1m 11s\n",
      "559:\tlearn: 0.6404743\ttotal: 1m 30s\tremaining: 1m 11s\n",
      "560:\tlearn: 0.6403920\ttotal: 1m 30s\tremaining: 1m 10s\n",
      "561:\tlearn: 0.6402411\ttotal: 1m 30s\tremaining: 1m 10s\n",
      "562:\tlearn: 0.6402010\ttotal: 1m 30s\tremaining: 1m 10s\n",
      "563:\tlearn: 0.6401423\ttotal: 1m 30s\tremaining: 1m 10s\n",
      "564:\tlearn: 0.6400409\ttotal: 1m 31s\tremaining: 1m 10s\n",
      "565:\tlearn: 0.6399278\ttotal: 1m 31s\tremaining: 1m 9s\n",
      "566:\tlearn: 0.6397969\ttotal: 1m 31s\tremaining: 1m 9s\n",
      "567:\tlearn: 0.6396538\ttotal: 1m 31s\tremaining: 1m 9s\n",
      "568:\tlearn: 0.6395645\ttotal: 1m 31s\tremaining: 1m 9s\n",
      "569:\tlearn: 0.6394981\ttotal: 1m 31s\tremaining: 1m 9s\n",
      "570:\tlearn: 0.6393462\ttotal: 1m 31s\tremaining: 1m 9s\n",
      "571:\tlearn: 0.6392302\ttotal: 1m 31s\tremaining: 1m 8s\n",
      "572:\tlearn: 0.6391085\ttotal: 1m 32s\tremaining: 1m 8s\n",
      "573:\tlearn: 0.6389367\ttotal: 1m 32s\tremaining: 1m 8s\n",
      "574:\tlearn: 0.6388543\ttotal: 1m 32s\tremaining: 1m 8s\n",
      "575:\tlearn: 0.6387784\ttotal: 1m 32s\tremaining: 1m 8s\n",
      "576:\tlearn: 0.6386581\ttotal: 1m 32s\tremaining: 1m 7s\n",
      "577:\tlearn: 0.6384310\ttotal: 1m 32s\tremaining: 1m 7s\n",
      "578:\tlearn: 0.6382815\ttotal: 1m 32s\tremaining: 1m 7s\n",
      "579:\tlearn: 0.6381715\ttotal: 1m 33s\tremaining: 1m 7s\n",
      "580:\tlearn: 0.6380010\ttotal: 1m 33s\tremaining: 1m 7s\n",
      "581:\tlearn: 0.6378950\ttotal: 1m 33s\tremaining: 1m 7s\n",
      "582:\tlearn: 0.6377242\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "583:\tlearn: 0.6376344\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "584:\tlearn: 0.6375139\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "585:\tlearn: 0.6374226\ttotal: 1m 33s\tremaining: 1m 6s\n",
      "586:\tlearn: 0.6372328\ttotal: 1m 34s\tremaining: 1m 6s\n",
      "587:\tlearn: 0.6370940\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "588:\tlearn: 0.6369778\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "589:\tlearn: 0.6369077\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "590:\tlearn: 0.6367814\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "591:\tlearn: 0.6366987\ttotal: 1m 34s\tremaining: 1m 5s\n",
      "592:\tlearn: 0.6366103\ttotal: 1m 35s\tremaining: 1m 5s\n",
      "593:\tlearn: 0.6364507\ttotal: 1m 35s\tremaining: 1m 5s\n",
      "594:\tlearn: 0.6363219\ttotal: 1m 35s\tremaining: 1m 5s\n",
      "595:\tlearn: 0.6362307\ttotal: 1m 35s\tremaining: 1m 4s\n",
      "596:\tlearn: 0.6360813\ttotal: 1m 35s\tremaining: 1m 4s\n",
      "597:\tlearn: 0.6359464\ttotal: 1m 36s\tremaining: 1m 4s\n",
      "598:\tlearn: 0.6358272\ttotal: 1m 36s\tremaining: 1m 4s\n",
      "599:\tlearn: 0.6356947\ttotal: 1m 36s\tremaining: 1m 4s\n",
      "600:\tlearn: 0.6355381\ttotal: 1m 36s\tremaining: 1m 4s\n",
      "601:\tlearn: 0.6353873\ttotal: 1m 37s\tremaining: 1m 4s\n",
      "602:\tlearn: 0.6352786\ttotal: 1m 37s\tremaining: 1m 3s\n",
      "603:\tlearn: 0.6351842\ttotal: 1m 37s\tremaining: 1m 3s\n",
      "604:\tlearn: 0.6350691\ttotal: 1m 37s\tremaining: 1m 3s\n",
      "605:\tlearn: 0.6349723\ttotal: 1m 37s\tremaining: 1m 3s\n",
      "606:\tlearn: 0.6348422\ttotal: 1m 37s\tremaining: 1m 3s\n",
      "607:\tlearn: 0.6347357\ttotal: 1m 38s\tremaining: 1m 3s\n",
      "608:\tlearn: 0.6346360\ttotal: 1m 38s\tremaining: 1m 3s\n",
      "609:\tlearn: 0.6345402\ttotal: 1m 38s\tremaining: 1m 2s\n",
      "610:\tlearn: 0.6344555\ttotal: 1m 38s\tremaining: 1m 2s\n",
      "611:\tlearn: 0.6343646\ttotal: 1m 38s\tremaining: 1m 2s\n",
      "612:\tlearn: 0.6342519\ttotal: 1m 38s\tremaining: 1m 2s\n",
      "613:\tlearn: 0.6341407\ttotal: 1m 38s\tremaining: 1m 2s\n",
      "614:\tlearn: 0.6340447\ttotal: 1m 38s\tremaining: 1m 1s\n",
      "615:\tlearn: 0.6339541\ttotal: 1m 39s\tremaining: 1m 1s\n",
      "616:\tlearn: 0.6338676\ttotal: 1m 39s\tremaining: 1m 1s\n",
      "617:\tlearn: 0.6337246\ttotal: 1m 39s\tremaining: 1m 1s\n",
      "618:\tlearn: 0.6335826\ttotal: 1m 39s\tremaining: 1m 1s\n",
      "619:\tlearn: 0.6335025\ttotal: 1m 39s\tremaining: 1m 1s\n",
      "620:\tlearn: 0.6333987\ttotal: 1m 39s\tremaining: 1m\n",
      "621:\tlearn: 0.6333026\ttotal: 1m 39s\tremaining: 1m\n",
      "622:\tlearn: 0.6331866\ttotal: 1m 40s\tremaining: 1m\n",
      "623:\tlearn: 0.6330645\ttotal: 1m 40s\tremaining: 1m\n",
      "624:\tlearn: 0.6329974\ttotal: 1m 40s\tremaining: 1m\n",
      "625:\tlearn: 0.6329050\ttotal: 1m 40s\tremaining: 60s\n",
      "626:\tlearn: 0.6327952\ttotal: 1m 40s\tremaining: 59.8s\n",
      "627:\tlearn: 0.6327121\ttotal: 1m 40s\tremaining: 59.6s\n",
      "628:\tlearn: 0.6326123\ttotal: 1m 40s\tremaining: 59.5s\n",
      "629:\tlearn: 0.6325056\ttotal: 1m 40s\tremaining: 59.3s\n",
      "630:\tlearn: 0.6324398\ttotal: 1m 41s\tremaining: 59.1s\n",
      "631:\tlearn: 0.6323208\ttotal: 1m 41s\tremaining: 58.9s\n",
      "632:\tlearn: 0.6321746\ttotal: 1m 41s\tremaining: 58.8s\n",
      "633:\tlearn: 0.6320389\ttotal: 1m 41s\tremaining: 58.6s\n",
      "634:\tlearn: 0.6319666\ttotal: 1m 41s\tremaining: 58.4s\n",
      "635:\tlearn: 0.6318490\ttotal: 1m 41s\tremaining: 58.2s\n",
      "636:\tlearn: 0.6317467\ttotal: 1m 41s\tremaining: 58s\n",
      "637:\tlearn: 0.6316465\ttotal: 1m 42s\tremaining: 57.9s\n",
      "638:\tlearn: 0.6315781\ttotal: 1m 42s\tremaining: 57.7s\n",
      "639:\tlearn: 0.6314607\ttotal: 1m 42s\tremaining: 57.5s\n",
      "640:\tlearn: 0.6313430\ttotal: 1m 42s\tremaining: 57.4s\n",
      "641:\tlearn: 0.6312481\ttotal: 1m 42s\tremaining: 57.2s\n",
      "642:\tlearn: 0.6311468\ttotal: 1m 42s\tremaining: 57s\n",
      "643:\tlearn: 0.6310401\ttotal: 1m 42s\tremaining: 56.8s\n",
      "644:\tlearn: 0.6309310\ttotal: 1m 42s\tremaining: 56.7s\n",
      "645:\tlearn: 0.6308566\ttotal: 1m 43s\tremaining: 56.5s\n",
      "646:\tlearn: 0.6307797\ttotal: 1m 43s\tremaining: 56.3s\n",
      "647:\tlearn: 0.6306937\ttotal: 1m 43s\tremaining: 56.1s\n",
      "648:\tlearn: 0.6305883\ttotal: 1m 43s\tremaining: 56s\n",
      "649:\tlearn: 0.6304652\ttotal: 1m 43s\tremaining: 55.8s\n",
      "650:\tlearn: 0.6303798\ttotal: 1m 43s\tremaining: 55.6s\n",
      "651:\tlearn: 0.6302769\ttotal: 1m 43s\tremaining: 55.4s\n",
      "652:\tlearn: 0.6301627\ttotal: 1m 44s\tremaining: 55.3s\n",
      "653:\tlearn: 0.6300491\ttotal: 1m 44s\tremaining: 55.1s\n",
      "654:\tlearn: 0.6298978\ttotal: 1m 44s\tremaining: 54.9s\n",
      "655:\tlearn: 0.6297899\ttotal: 1m 44s\tremaining: 54.8s\n",
      "656:\tlearn: 0.6296928\ttotal: 1m 44s\tremaining: 54.6s\n",
      "657:\tlearn: 0.6295884\ttotal: 1m 44s\tremaining: 54.4s\n",
      "658:\tlearn: 0.6294514\ttotal: 1m 44s\tremaining: 54.2s\n",
      "659:\tlearn: 0.6293400\ttotal: 1m 44s\tremaining: 54.1s\n",
      "660:\tlearn: 0.6292022\ttotal: 1m 45s\tremaining: 53.9s\n",
      "661:\tlearn: 0.6291112\ttotal: 1m 45s\tremaining: 53.7s\n",
      "662:\tlearn: 0.6290413\ttotal: 1m 45s\tremaining: 53.6s\n",
      "663:\tlearn: 0.6289250\ttotal: 1m 45s\tremaining: 53.4s\n",
      "664:\tlearn: 0.6287959\ttotal: 1m 45s\tremaining: 53.2s\n",
      "665:\tlearn: 0.6286433\ttotal: 1m 45s\tremaining: 53.1s\n",
      "666:\tlearn: 0.6285248\ttotal: 1m 45s\tremaining: 52.9s\n",
      "667:\tlearn: 0.6284450\ttotal: 1m 46s\tremaining: 52.7s\n",
      "668:\tlearn: 0.6283879\ttotal: 1m 46s\tremaining: 52.5s\n",
      "669:\tlearn: 0.6282861\ttotal: 1m 46s\tremaining: 52.4s\n",
      "670:\tlearn: 0.6281336\ttotal: 1m 46s\tremaining: 52.2s\n",
      "671:\tlearn: 0.6280430\ttotal: 1m 46s\tremaining: 52s\n",
      "672:\tlearn: 0.6279019\ttotal: 1m 46s\tremaining: 51.9s\n",
      "673:\tlearn: 0.6278087\ttotal: 1m 46s\tremaining: 51.7s\n",
      "674:\tlearn: 0.6276987\ttotal: 1m 47s\tremaining: 51.5s\n",
      "675:\tlearn: 0.6276002\ttotal: 1m 47s\tremaining: 51.4s\n",
      "676:\tlearn: 0.6274815\ttotal: 1m 47s\tremaining: 51.2s\n",
      "677:\tlearn: 0.6273685\ttotal: 1m 47s\tremaining: 51s\n",
      "678:\tlearn: 0.6271956\ttotal: 1m 47s\tremaining: 50.9s\n",
      "679:\tlearn: 0.6270941\ttotal: 1m 47s\tremaining: 50.7s\n",
      "680:\tlearn: 0.6269240\ttotal: 1m 47s\tremaining: 50.5s\n",
      "681:\tlearn: 0.6268218\ttotal: 1m 47s\tremaining: 50.4s\n",
      "682:\tlearn: 0.6266798\ttotal: 1m 48s\tremaining: 50.2s\n",
      "683:\tlearn: 0.6265157\ttotal: 1m 48s\tremaining: 50.1s\n",
      "684:\tlearn: 0.6263842\ttotal: 1m 48s\tremaining: 49.9s\n",
      "685:\tlearn: 0.6262968\ttotal: 1m 48s\tremaining: 49.7s\n",
      "686:\tlearn: 0.6261568\ttotal: 1m 48s\tremaining: 49.6s\n",
      "687:\tlearn: 0.6259842\ttotal: 1m 49s\tremaining: 49.5s\n",
      "688:\tlearn: 0.6258895\ttotal: 1m 49s\tremaining: 49.4s\n",
      "689:\tlearn: 0.6257656\ttotal: 1m 49s\tremaining: 49.2s\n",
      "690:\tlearn: 0.6256562\ttotal: 1m 49s\tremaining: 49.1s\n",
      "691:\tlearn: 0.6254886\ttotal: 1m 49s\tremaining: 49s\n",
      "692:\tlearn: 0.6253836\ttotal: 1m 50s\tremaining: 48.8s\n",
      "693:\tlearn: 0.6253084\ttotal: 1m 50s\tremaining: 48.7s\n",
      "694:\tlearn: 0.6252024\ttotal: 1m 50s\tremaining: 48.5s\n",
      "695:\tlearn: 0.6251371\ttotal: 1m 50s\tremaining: 48.4s\n",
      "696:\tlearn: 0.6250608\ttotal: 1m 50s\tremaining: 48.2s\n",
      "697:\tlearn: 0.6249360\ttotal: 1m 51s\tremaining: 48.1s\n",
      "698:\tlearn: 0.6248468\ttotal: 1m 51s\tremaining: 47.9s\n",
      "699:\tlearn: 0.6247234\ttotal: 1m 51s\tremaining: 47.8s\n",
      "700:\tlearn: 0.6246168\ttotal: 1m 51s\tremaining: 47.7s\n",
      "701:\tlearn: 0.6245413\ttotal: 1m 51s\tremaining: 47.5s\n",
      "702:\tlearn: 0.6244115\ttotal: 1m 51s\tremaining: 47.3s\n",
      "703:\tlearn: 0.6243301\ttotal: 1m 52s\tremaining: 47.1s\n",
      "704:\tlearn: 0.6242392\ttotal: 1m 52s\tremaining: 47s\n",
      "705:\tlearn: 0.6241510\ttotal: 1m 52s\tremaining: 46.8s\n",
      "706:\tlearn: 0.6240585\ttotal: 1m 52s\tremaining: 46.6s\n",
      "707:\tlearn: 0.6239458\ttotal: 1m 52s\tremaining: 46.5s\n",
      "708:\tlearn: 0.6238099\ttotal: 1m 52s\tremaining: 46.3s\n",
      "709:\tlearn: 0.6237381\ttotal: 1m 52s\tremaining: 46.1s\n",
      "710:\tlearn: 0.6236480\ttotal: 1m 53s\tremaining: 46s\n",
      "711:\tlearn: 0.6235784\ttotal: 1m 53s\tremaining: 45.8s\n",
      "712:\tlearn: 0.6234698\ttotal: 1m 53s\tremaining: 45.6s\n",
      "713:\tlearn: 0.6233890\ttotal: 1m 53s\tremaining: 45.4s\n",
      "714:\tlearn: 0.6232955\ttotal: 1m 53s\tremaining: 45.3s\n",
      "715:\tlearn: 0.6231949\ttotal: 1m 53s\tremaining: 45.1s\n",
      "716:\tlearn: 0.6231468\ttotal: 1m 53s\tremaining: 44.9s\n",
      "717:\tlearn: 0.6229870\ttotal: 1m 53s\tremaining: 44.8s\n",
      "718:\tlearn: 0.6229382\ttotal: 1m 54s\tremaining: 44.6s\n",
      "719:\tlearn: 0.6228739\ttotal: 1m 54s\tremaining: 44.4s\n",
      "720:\tlearn: 0.6227964\ttotal: 1m 54s\tremaining: 44.2s\n",
      "721:\tlearn: 0.6227186\ttotal: 1m 54s\tremaining: 44.1s\n",
      "722:\tlearn: 0.6226135\ttotal: 1m 54s\tremaining: 43.9s\n",
      "723:\tlearn: 0.6224886\ttotal: 1m 54s\tremaining: 43.7s\n",
      "724:\tlearn: 0.6223593\ttotal: 1m 54s\tremaining: 43.6s\n",
      "725:\tlearn: 0.6222868\ttotal: 1m 54s\tremaining: 43.4s\n",
      "726:\tlearn: 0.6221802\ttotal: 1m 55s\tremaining: 43.2s\n",
      "727:\tlearn: 0.6221160\ttotal: 1m 55s\tremaining: 43.1s\n",
      "728:\tlearn: 0.6220392\ttotal: 1m 55s\tremaining: 42.9s\n",
      "729:\tlearn: 0.6219600\ttotal: 1m 55s\tremaining: 42.7s\n",
      "730:\tlearn: 0.6218746\ttotal: 1m 55s\tremaining: 42.6s\n",
      "731:\tlearn: 0.6217980\ttotal: 1m 55s\tremaining: 42.4s\n",
      "732:\tlearn: 0.6216505\ttotal: 1m 55s\tremaining: 42.2s\n",
      "733:\tlearn: 0.6215962\ttotal: 1m 56s\tremaining: 42.1s\n",
      "734:\tlearn: 0.6214883\ttotal: 1m 56s\tremaining: 41.9s\n",
      "735:\tlearn: 0.6213717\ttotal: 1m 56s\tremaining: 41.7s\n",
      "736:\tlearn: 0.6212616\ttotal: 1m 56s\tremaining: 41.6s\n",
      "737:\tlearn: 0.6211998\ttotal: 1m 56s\tremaining: 41.4s\n",
      "738:\tlearn: 0.6211180\ttotal: 1m 56s\tremaining: 41.2s\n",
      "739:\tlearn: 0.6210276\ttotal: 1m 56s\tremaining: 41.1s\n",
      "740:\tlearn: 0.6209692\ttotal: 1m 56s\tremaining: 40.9s\n",
      "741:\tlearn: 0.6208830\ttotal: 1m 57s\tremaining: 40.7s\n",
      "742:\tlearn: 0.6207871\ttotal: 1m 57s\tremaining: 40.5s\n",
      "743:\tlearn: 0.6207157\ttotal: 1m 57s\tremaining: 40.4s\n",
      "744:\tlearn: 0.6206406\ttotal: 1m 57s\tremaining: 40.2s\n",
      "745:\tlearn: 0.6205517\ttotal: 1m 57s\tremaining: 40s\n",
      "746:\tlearn: 0.6204238\ttotal: 1m 57s\tremaining: 39.9s\n",
      "747:\tlearn: 0.6203499\ttotal: 1m 57s\tremaining: 39.7s\n",
      "748:\tlearn: 0.6202494\ttotal: 1m 58s\tremaining: 39.5s\n",
      "749:\tlearn: 0.6201510\ttotal: 1m 58s\tremaining: 39.4s\n",
      "750:\tlearn: 0.6200565\ttotal: 1m 58s\tremaining: 39.2s\n",
      "751:\tlearn: 0.6199326\ttotal: 1m 58s\tremaining: 39.1s\n",
      "752:\tlearn: 0.6197952\ttotal: 1m 58s\tremaining: 38.9s\n",
      "753:\tlearn: 0.6197098\ttotal: 1m 58s\tremaining: 38.7s\n",
      "754:\tlearn: 0.6196157\ttotal: 1m 58s\tremaining: 38.6s\n",
      "755:\tlearn: 0.6195660\ttotal: 1m 58s\tremaining: 38.4s\n",
      "756:\tlearn: 0.6194494\ttotal: 1m 59s\tremaining: 38.2s\n",
      "757:\tlearn: 0.6193437\ttotal: 1m 59s\tremaining: 38.1s\n",
      "758:\tlearn: 0.6192754\ttotal: 1m 59s\tremaining: 37.9s\n",
      "759:\tlearn: 0.6191864\ttotal: 1m 59s\tremaining: 37.7s\n",
      "760:\tlearn: 0.6190591\ttotal: 1m 59s\tremaining: 37.6s\n",
      "761:\tlearn: 0.6189556\ttotal: 1m 59s\tremaining: 37.4s\n",
      "762:\tlearn: 0.6188608\ttotal: 1m 59s\tremaining: 37.3s\n",
      "763:\tlearn: 0.6187283\ttotal: 2m\tremaining: 37.1s\n",
      "764:\tlearn: 0.6186424\ttotal: 2m\tremaining: 36.9s\n",
      "765:\tlearn: 0.6185529\ttotal: 2m\tremaining: 36.8s\n",
      "766:\tlearn: 0.6184269\ttotal: 2m\tremaining: 36.6s\n",
      "767:\tlearn: 0.6182462\ttotal: 2m\tremaining: 36.4s\n",
      "768:\tlearn: 0.6181011\ttotal: 2m\tremaining: 36.3s\n",
      "769:\tlearn: 0.6180195\ttotal: 2m\tremaining: 36.1s\n",
      "770:\tlearn: 0.6179082\ttotal: 2m 1s\tremaining: 36s\n",
      "771:\tlearn: 0.6178403\ttotal: 2m 1s\tremaining: 35.8s\n",
      "772:\tlearn: 0.6177546\ttotal: 2m 1s\tremaining: 35.6s\n",
      "773:\tlearn: 0.6176660\ttotal: 2m 1s\tremaining: 35.5s\n",
      "774:\tlearn: 0.6175540\ttotal: 2m 1s\tremaining: 35.3s\n",
      "775:\tlearn: 0.6174445\ttotal: 2m 1s\tremaining: 35.1s\n",
      "776:\tlearn: 0.6173586\ttotal: 2m 1s\tremaining: 35s\n",
      "777:\tlearn: 0.6172353\ttotal: 2m 2s\tremaining: 34.9s\n",
      "778:\tlearn: 0.6171688\ttotal: 2m 2s\tremaining: 34.7s\n",
      "779:\tlearn: 0.6170713\ttotal: 2m 2s\tremaining: 34.6s\n",
      "780:\tlearn: 0.6169596\ttotal: 2m 2s\tremaining: 34.4s\n",
      "781:\tlearn: 0.6168563\ttotal: 2m 2s\tremaining: 34.3s\n",
      "782:\tlearn: 0.6168118\ttotal: 2m 3s\tremaining: 34.1s\n",
      "783:\tlearn: 0.6167538\ttotal: 2m 3s\tremaining: 34s\n",
      "784:\tlearn: 0.6166291\ttotal: 2m 3s\tremaining: 33.8s\n",
      "785:\tlearn: 0.6165398\ttotal: 2m 3s\tremaining: 33.7s\n",
      "786:\tlearn: 0.6164016\ttotal: 2m 3s\tremaining: 33.6s\n",
      "787:\tlearn: 0.6162993\ttotal: 2m 4s\tremaining: 33.4s\n",
      "788:\tlearn: 0.6161678\ttotal: 2m 4s\tremaining: 33.3s\n",
      "789:\tlearn: 0.6160702\ttotal: 2m 4s\tremaining: 33.1s\n",
      "790:\tlearn: 0.6160048\ttotal: 2m 4s\tremaining: 33s\n",
      "791:\tlearn: 0.6159253\ttotal: 2m 5s\tremaining: 32.8s\n",
      "792:\tlearn: 0.6158260\ttotal: 2m 5s\tremaining: 32.7s\n",
      "793:\tlearn: 0.6157180\ttotal: 2m 5s\tremaining: 32.5s\n",
      "794:\tlearn: 0.6156072\ttotal: 2m 5s\tremaining: 32.4s\n",
      "795:\tlearn: 0.6155326\ttotal: 2m 5s\tremaining: 32.2s\n",
      "796:\tlearn: 0.6154423\ttotal: 2m 5s\tremaining: 32.1s\n",
      "797:\tlearn: 0.6153844\ttotal: 2m 5s\tremaining: 31.9s\n",
      "798:\tlearn: 0.6153296\ttotal: 2m 6s\tremaining: 31.7s\n",
      "799:\tlearn: 0.6152524\ttotal: 2m 6s\tremaining: 31.6s\n",
      "800:\tlearn: 0.6151315\ttotal: 2m 6s\tremaining: 31.4s\n",
      "801:\tlearn: 0.6150420\ttotal: 2m 6s\tremaining: 31.2s\n",
      "802:\tlearn: 0.6149568\ttotal: 2m 6s\tremaining: 31.1s\n",
      "803:\tlearn: 0.6148865\ttotal: 2m 6s\tremaining: 30.9s\n",
      "804:\tlearn: 0.6148199\ttotal: 2m 6s\tremaining: 30.7s\n",
      "805:\tlearn: 0.6147602\ttotal: 2m 7s\tremaining: 30.6s\n",
      "806:\tlearn: 0.6146606\ttotal: 2m 7s\tremaining: 30.4s\n",
      "807:\tlearn: 0.6145982\ttotal: 2m 7s\tremaining: 30.2s\n",
      "808:\tlearn: 0.6144996\ttotal: 2m 7s\tremaining: 30.1s\n",
      "809:\tlearn: 0.6144061\ttotal: 2m 7s\tremaining: 29.9s\n",
      "810:\tlearn: 0.6143023\ttotal: 2m 7s\tremaining: 29.8s\n",
      "811:\tlearn: 0.6142021\ttotal: 2m 7s\tremaining: 29.6s\n",
      "812:\tlearn: 0.6141016\ttotal: 2m 7s\tremaining: 29.4s\n",
      "813:\tlearn: 0.6140452\ttotal: 2m 8s\tremaining: 29.3s\n",
      "814:\tlearn: 0.6139470\ttotal: 2m 8s\tremaining: 29.1s\n",
      "815:\tlearn: 0.6138467\ttotal: 2m 8s\tremaining: 28.9s\n",
      "816:\tlearn: 0.6136938\ttotal: 2m 8s\tremaining: 28.8s\n",
      "817:\tlearn: 0.6135752\ttotal: 2m 8s\tremaining: 28.6s\n",
      "818:\tlearn: 0.6135248\ttotal: 2m 8s\tremaining: 28.5s\n",
      "819:\tlearn: 0.6134197\ttotal: 2m 8s\tremaining: 28.3s\n",
      "820:\tlearn: 0.6133181\ttotal: 2m 9s\tremaining: 28.1s\n",
      "821:\tlearn: 0.6132193\ttotal: 2m 9s\tremaining: 28s\n",
      "822:\tlearn: 0.6131062\ttotal: 2m 9s\tremaining: 27.8s\n",
      "823:\tlearn: 0.6130119\ttotal: 2m 9s\tremaining: 27.7s\n",
      "824:\tlearn: 0.6128938\ttotal: 2m 9s\tremaining: 27.5s\n",
      "825:\tlearn: 0.6128127\ttotal: 2m 9s\tremaining: 27.3s\n",
      "826:\tlearn: 0.6127546\ttotal: 2m 9s\tremaining: 27.2s\n",
      "827:\tlearn: 0.6126690\ttotal: 2m 9s\tremaining: 27s\n",
      "828:\tlearn: 0.6125104\ttotal: 2m 10s\tremaining: 26.8s\n",
      "829:\tlearn: 0.6124576\ttotal: 2m 10s\tremaining: 26.7s\n",
      "830:\tlearn: 0.6123449\ttotal: 2m 10s\tremaining: 26.5s\n",
      "831:\tlearn: 0.6122582\ttotal: 2m 10s\tremaining: 26.3s\n",
      "832:\tlearn: 0.6121213\ttotal: 2m 10s\tremaining: 26.2s\n",
      "833:\tlearn: 0.6120157\ttotal: 2m 10s\tremaining: 26s\n",
      "834:\tlearn: 0.6119394\ttotal: 2m 10s\tremaining: 25.9s\n",
      "835:\tlearn: 0.6118374\ttotal: 2m 11s\tremaining: 25.7s\n",
      "836:\tlearn: 0.6117590\ttotal: 2m 11s\tremaining: 25.5s\n",
      "837:\tlearn: 0.6116688\ttotal: 2m 11s\tremaining: 25.4s\n",
      "838:\tlearn: 0.6115945\ttotal: 2m 11s\tremaining: 25.2s\n",
      "839:\tlearn: 0.6114825\ttotal: 2m 11s\tremaining: 25.1s\n",
      "840:\tlearn: 0.6114036\ttotal: 2m 11s\tremaining: 24.9s\n",
      "841:\tlearn: 0.6113031\ttotal: 2m 11s\tremaining: 24.7s\n",
      "842:\tlearn: 0.6112210\ttotal: 2m 11s\tremaining: 24.6s\n",
      "843:\tlearn: 0.6111370\ttotal: 2m 12s\tremaining: 24.4s\n",
      "844:\tlearn: 0.6110681\ttotal: 2m 12s\tremaining: 24.3s\n",
      "845:\tlearn: 0.6108693\ttotal: 2m 12s\tremaining: 24.1s\n",
      "846:\tlearn: 0.6107615\ttotal: 2m 12s\tremaining: 23.9s\n",
      "847:\tlearn: 0.6107184\ttotal: 2m 12s\tremaining: 23.8s\n",
      "848:\tlearn: 0.6106192\ttotal: 2m 12s\tremaining: 23.6s\n",
      "849:\tlearn: 0.6105320\ttotal: 2m 12s\tremaining: 23.5s\n",
      "850:\tlearn: 0.6104243\ttotal: 2m 13s\tremaining: 23.3s\n",
      "851:\tlearn: 0.6103300\ttotal: 2m 13s\tremaining: 23.1s\n",
      "852:\tlearn: 0.6102432\ttotal: 2m 13s\tremaining: 23s\n",
      "853:\tlearn: 0.6101947\ttotal: 2m 13s\tremaining: 22.8s\n",
      "854:\tlearn: 0.6101041\ttotal: 2m 13s\tremaining: 22.7s\n",
      "855:\tlearn: 0.6100355\ttotal: 2m 13s\tremaining: 22.5s\n",
      "856:\tlearn: 0.6099524\ttotal: 2m 13s\tremaining: 22.3s\n",
      "857:\tlearn: 0.6098641\ttotal: 2m 13s\tremaining: 22.2s\n",
      "858:\tlearn: 0.6097697\ttotal: 2m 14s\tremaining: 22s\n",
      "859:\tlearn: 0.6096967\ttotal: 2m 14s\tremaining: 21.9s\n",
      "860:\tlearn: 0.6096242\ttotal: 2m 14s\tremaining: 21.7s\n",
      "861:\tlearn: 0.6095569\ttotal: 2m 14s\tremaining: 21.5s\n",
      "862:\tlearn: 0.6094912\ttotal: 2m 14s\tremaining: 21.4s\n",
      "863:\tlearn: 0.6094207\ttotal: 2m 14s\tremaining: 21.2s\n",
      "864:\tlearn: 0.6093838\ttotal: 2m 14s\tremaining: 21s\n",
      "865:\tlearn: 0.6092445\ttotal: 2m 15s\tremaining: 20.9s\n",
      "866:\tlearn: 0.6091644\ttotal: 2m 15s\tremaining: 20.7s\n",
      "867:\tlearn: 0.6090884\ttotal: 2m 15s\tremaining: 20.6s\n",
      "868:\tlearn: 0.6090136\ttotal: 2m 15s\tremaining: 20.4s\n",
      "869:\tlearn: 0.6089613\ttotal: 2m 15s\tremaining: 20.3s\n",
      "870:\tlearn: 0.6088156\ttotal: 2m 15s\tremaining: 20.1s\n",
      "871:\tlearn: 0.6087454\ttotal: 2m 15s\tremaining: 19.9s\n",
      "872:\tlearn: 0.6086553\ttotal: 2m 16s\tremaining: 19.8s\n",
      "873:\tlearn: 0.6085830\ttotal: 2m 16s\tremaining: 19.6s\n",
      "874:\tlearn: 0.6085104\ttotal: 2m 16s\tremaining: 19.5s\n",
      "875:\tlearn: 0.6084080\ttotal: 2m 16s\tremaining: 19.3s\n",
      "876:\tlearn: 0.6083278\ttotal: 2m 16s\tremaining: 19.2s\n",
      "877:\tlearn: 0.6082578\ttotal: 2m 17s\tremaining: 19s\n",
      "878:\tlearn: 0.6081251\ttotal: 2m 17s\tremaining: 18.9s\n",
      "879:\tlearn: 0.6080523\ttotal: 2m 17s\tremaining: 18.7s\n",
      "880:\tlearn: 0.6079751\ttotal: 2m 17s\tremaining: 18.6s\n",
      "881:\tlearn: 0.6079006\ttotal: 2m 17s\tremaining: 18.4s\n",
      "882:\tlearn: 0.6078462\ttotal: 2m 17s\tremaining: 18.3s\n",
      "883:\tlearn: 0.6077532\ttotal: 2m 18s\tremaining: 18.1s\n",
      "884:\tlearn: 0.6076199\ttotal: 2m 18s\tremaining: 18s\n",
      "885:\tlearn: 0.6075270\ttotal: 2m 18s\tremaining: 17.8s\n",
      "886:\tlearn: 0.6074483\ttotal: 2m 18s\tremaining: 17.7s\n",
      "887:\tlearn: 0.6073144\ttotal: 2m 18s\tremaining: 17.5s\n",
      "888:\tlearn: 0.6071936\ttotal: 2m 19s\tremaining: 17.4s\n",
      "889:\tlearn: 0.6070821\ttotal: 2m 19s\tremaining: 17.2s\n",
      "890:\tlearn: 0.6069728\ttotal: 2m 19s\tremaining: 17.1s\n",
      "891:\tlearn: 0.6069035\ttotal: 2m 19s\tremaining: 16.9s\n",
      "892:\tlearn: 0.6068439\ttotal: 2m 19s\tremaining: 16.7s\n",
      "893:\tlearn: 0.6067137\ttotal: 2m 19s\tremaining: 16.6s\n",
      "894:\tlearn: 0.6066368\ttotal: 2m 19s\tremaining: 16.4s\n",
      "895:\tlearn: 0.6065215\ttotal: 2m 20s\tremaining: 16.3s\n",
      "896:\tlearn: 0.6064241\ttotal: 2m 20s\tremaining: 16.1s\n",
      "897:\tlearn: 0.6062620\ttotal: 2m 20s\tremaining: 15.9s\n",
      "898:\tlearn: 0.6061562\ttotal: 2m 20s\tremaining: 15.8s\n",
      "899:\tlearn: 0.6060801\ttotal: 2m 20s\tremaining: 15.6s\n",
      "900:\tlearn: 0.6060154\ttotal: 2m 20s\tremaining: 15.5s\n",
      "901:\tlearn: 0.6059225\ttotal: 2m 20s\tremaining: 15.3s\n",
      "902:\tlearn: 0.6058630\ttotal: 2m 21s\tremaining: 15.1s\n",
      "903:\tlearn: 0.6057963\ttotal: 2m 21s\tremaining: 15s\n",
      "904:\tlearn: 0.6056460\ttotal: 2m 21s\tremaining: 14.8s\n",
      "905:\tlearn: 0.6055509\ttotal: 2m 21s\tremaining: 14.7s\n",
      "906:\tlearn: 0.6054649\ttotal: 2m 21s\tremaining: 14.5s\n",
      "907:\tlearn: 0.6053902\ttotal: 2m 21s\tremaining: 14.4s\n",
      "908:\tlearn: 0.6053040\ttotal: 2m 21s\tremaining: 14.2s\n",
      "909:\tlearn: 0.6052200\ttotal: 2m 21s\tremaining: 14s\n",
      "910:\tlearn: 0.6051274\ttotal: 2m 22s\tremaining: 13.9s\n",
      "911:\tlearn: 0.6050122\ttotal: 2m 22s\tremaining: 13.7s\n",
      "912:\tlearn: 0.6049407\ttotal: 2m 22s\tremaining: 13.6s\n",
      "913:\tlearn: 0.6048622\ttotal: 2m 22s\tremaining: 13.4s\n",
      "914:\tlearn: 0.6047737\ttotal: 2m 22s\tremaining: 13.2s\n",
      "915:\tlearn: 0.6046661\ttotal: 2m 22s\tremaining: 13.1s\n",
      "916:\tlearn: 0.6045986\ttotal: 2m 22s\tremaining: 12.9s\n",
      "917:\tlearn: 0.6045022\ttotal: 2m 23s\tremaining: 12.8s\n",
      "918:\tlearn: 0.6044242\ttotal: 2m 23s\tremaining: 12.6s\n",
      "919:\tlearn: 0.6043360\ttotal: 2m 23s\tremaining: 12.5s\n",
      "920:\tlearn: 0.6042777\ttotal: 2m 23s\tremaining: 12.3s\n",
      "921:\tlearn: 0.6041782\ttotal: 2m 23s\tremaining: 12.1s\n",
      "922:\tlearn: 0.6041242\ttotal: 2m 23s\tremaining: 12s\n",
      "923:\tlearn: 0.6039942\ttotal: 2m 23s\tremaining: 11.8s\n",
      "924:\tlearn: 0.6038456\ttotal: 2m 23s\tremaining: 11.7s\n",
      "925:\tlearn: 0.6037074\ttotal: 2m 24s\tremaining: 11.5s\n",
      "926:\tlearn: 0.6036061\ttotal: 2m 24s\tremaining: 11.4s\n",
      "927:\tlearn: 0.6035574\ttotal: 2m 24s\tremaining: 11.2s\n",
      "928:\tlearn: 0.6034591\ttotal: 2m 24s\tremaining: 11s\n",
      "929:\tlearn: 0.6033285\ttotal: 2m 24s\tremaining: 10.9s\n",
      "930:\tlearn: 0.6032457\ttotal: 2m 24s\tremaining: 10.7s\n",
      "931:\tlearn: 0.6031649\ttotal: 2m 24s\tremaining: 10.6s\n",
      "932:\tlearn: 0.6031173\ttotal: 2m 25s\tremaining: 10.4s\n",
      "933:\tlearn: 0.6030487\ttotal: 2m 25s\tremaining: 10.3s\n",
      "934:\tlearn: 0.6029879\ttotal: 2m 25s\tremaining: 10.1s\n",
      "935:\tlearn: 0.6029359\ttotal: 2m 25s\tremaining: 9.94s\n",
      "936:\tlearn: 0.6028263\ttotal: 2m 25s\tremaining: 9.78s\n",
      "937:\tlearn: 0.6027344\ttotal: 2m 25s\tremaining: 9.63s\n",
      "938:\tlearn: 0.6026679\ttotal: 2m 25s\tremaining: 9.47s\n",
      "939:\tlearn: 0.6025267\ttotal: 2m 25s\tremaining: 9.31s\n",
      "940:\tlearn: 0.6024335\ttotal: 2m 26s\tremaining: 9.16s\n",
      "941:\tlearn: 0.6023313\ttotal: 2m 26s\tremaining: 9s\n",
      "942:\tlearn: 0.6022522\ttotal: 2m 26s\tremaining: 8.85s\n",
      "943:\tlearn: 0.6021938\ttotal: 2m 26s\tremaining: 8.69s\n",
      "944:\tlearn: 0.6020539\ttotal: 2m 26s\tremaining: 8.53s\n",
      "945:\tlearn: 0.6019907\ttotal: 2m 26s\tremaining: 8.38s\n",
      "946:\tlearn: 0.6019040\ttotal: 2m 26s\tremaining: 8.22s\n",
      "947:\tlearn: 0.6018219\ttotal: 2m 27s\tremaining: 8.07s\n",
      "948:\tlearn: 0.6016917\ttotal: 2m 27s\tremaining: 7.92s\n",
      "949:\tlearn: 0.6015548\ttotal: 2m 27s\tremaining: 7.77s\n",
      "950:\tlearn: 0.6015058\ttotal: 2m 27s\tremaining: 7.61s\n",
      "951:\tlearn: 0.6014068\ttotal: 2m 27s\tremaining: 7.45s\n",
      "952:\tlearn: 0.6013052\ttotal: 2m 27s\tremaining: 7.3s\n",
      "953:\tlearn: 0.6011979\ttotal: 2m 28s\tremaining: 7.14s\n",
      "954:\tlearn: 0.6011211\ttotal: 2m 28s\tremaining: 6.99s\n",
      "955:\tlearn: 0.6010676\ttotal: 2m 28s\tremaining: 6.83s\n",
      "956:\tlearn: 0.6010094\ttotal: 2m 28s\tremaining: 6.67s\n",
      "957:\tlearn: 0.6009701\ttotal: 2m 28s\tremaining: 6.51s\n",
      "958:\tlearn: 0.6009040\ttotal: 2m 28s\tremaining: 6.36s\n",
      "959:\tlearn: 0.6008537\ttotal: 2m 28s\tremaining: 6.2s\n",
      "960:\tlearn: 0.6007410\ttotal: 2m 29s\tremaining: 6.05s\n",
      "961:\tlearn: 0.6006702\ttotal: 2m 29s\tremaining: 5.89s\n",
      "962:\tlearn: 0.6005747\ttotal: 2m 29s\tremaining: 5.74s\n",
      "963:\tlearn: 0.6005051\ttotal: 2m 29s\tremaining: 5.58s\n",
      "964:\tlearn: 0.6004515\ttotal: 2m 29s\tremaining: 5.42s\n",
      "965:\tlearn: 0.6003067\ttotal: 2m 29s\tremaining: 5.27s\n",
      "966:\tlearn: 0.6001967\ttotal: 2m 29s\tremaining: 5.12s\n",
      "967:\tlearn: 0.6000981\ttotal: 2m 30s\tremaining: 4.96s\n",
      "968:\tlearn: 0.6000137\ttotal: 2m 30s\tremaining: 4.81s\n",
      "969:\tlearn: 0.5999591\ttotal: 2m 30s\tremaining: 4.66s\n",
      "970:\tlearn: 0.5999009\ttotal: 2m 30s\tremaining: 4.5s\n",
      "971:\tlearn: 0.5998445\ttotal: 2m 30s\tremaining: 4.35s\n",
      "972:\tlearn: 0.5997868\ttotal: 2m 31s\tremaining: 4.19s\n",
      "973:\tlearn: 0.5997129\ttotal: 2m 31s\tremaining: 4.04s\n",
      "974:\tlearn: 0.5996354\ttotal: 2m 31s\tremaining: 3.88s\n",
      "975:\tlearn: 0.5995386\ttotal: 2m 31s\tremaining: 3.73s\n",
      "976:\tlearn: 0.5994478\ttotal: 2m 31s\tremaining: 3.58s\n",
      "977:\tlearn: 0.5993923\ttotal: 2m 32s\tremaining: 3.42s\n",
      "978:\tlearn: 0.5993173\ttotal: 2m 32s\tremaining: 3.27s\n",
      "979:\tlearn: 0.5992052\ttotal: 2m 32s\tremaining: 3.11s\n",
      "980:\tlearn: 0.5991682\ttotal: 2m 32s\tremaining: 2.96s\n",
      "981:\tlearn: 0.5990971\ttotal: 2m 32s\tremaining: 2.8s\n",
      "982:\tlearn: 0.5990559\ttotal: 2m 33s\tremaining: 2.65s\n",
      "983:\tlearn: 0.5989841\ttotal: 2m 33s\tremaining: 2.49s\n",
      "984:\tlearn: 0.5989415\ttotal: 2m 33s\tremaining: 2.33s\n",
      "985:\tlearn: 0.5988594\ttotal: 2m 33s\tremaining: 2.18s\n",
      "986:\tlearn: 0.5987871\ttotal: 2m 33s\tremaining: 2.02s\n",
      "987:\tlearn: 0.5987352\ttotal: 2m 33s\tremaining: 1.87s\n",
      "988:\tlearn: 0.5986300\ttotal: 2m 33s\tremaining: 1.71s\n",
      "989:\tlearn: 0.5985564\ttotal: 2m 33s\tremaining: 1.55s\n",
      "990:\tlearn: 0.5984772\ttotal: 2m 34s\tremaining: 1.4s\n",
      "991:\tlearn: 0.5984361\ttotal: 2m 34s\tremaining: 1.24s\n",
      "992:\tlearn: 0.5983345\ttotal: 2m 34s\tremaining: 1.09s\n",
      "993:\tlearn: 0.5983023\ttotal: 2m 34s\tremaining: 933ms\n",
      "994:\tlearn: 0.5981807\ttotal: 2m 34s\tremaining: 777ms\n",
      "995:\tlearn: 0.5981144\ttotal: 2m 34s\tremaining: 622ms\n",
      "996:\tlearn: 0.5980452\ttotal: 2m 34s\tremaining: 466ms\n",
      "997:\tlearn: 0.5980017\ttotal: 2m 35s\tremaining: 311ms\n",
      "998:\tlearn: 0.5979546\ttotal: 2m 35s\tremaining: 155ms\n",
      "999:\tlearn: 0.5978558\ttotal: 2m 35s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 &lt;catboost.core.CatBoostClassifier object at 0x7f2de1adde10&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 &lt;catboost.core.CatBoostClassifier object at 0x7f2de1adde10&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01, ngram_range=(3, 5))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x7f2de1adde10&gt;</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='char_wb', max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                ('clf',\n",
       "                 <catboost.core.CatBoostClassifier object at 0x7f2de1adde10>)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Build pipline with GPUs\n",
    "pipe_tfidf3 = Pipeline([('tfidf', TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=.01, max_df=.3)), ('clf', CatBoostClassifier(task_type='GPU', devices='0:1'))])\n",
    "\n",
    "pipe_tfidf3.fit(X_train4, y_train4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "BuIGpXOY2omY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuIGpXOY2omY",
    "outputId": "1673339b-b6c9-4a52-e9f1-b0976b1171f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59      1666\n",
      "           1       0.72      0.72      0.72      1667\n",
      "           2       0.70      0.76      0.73      1667\n",
      "\n",
      "    accuracy                           0.68      5000\n",
      "   macro avg       0.68      0.68      0.68      5000\n",
      "weighted avg       0.68      0.68      0.68      5000\n",
      "\n",
      "accuracy: 0.681\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe_tfidf3, X_test4, y_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "InPVFKfFVy_C",
   "metadata": {
    "id": "InPVFKfFVy_C"
   },
   "source": [
    "Catboost is the best single model result over all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "-4f6Sl2F_wMU",
   "metadata": {
    "id": "-4f6Sl2F_wMU"
   },
   "outputs": [],
   "source": [
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(reviews.text, reviews.label, test_size=0.05, \n",
    "                                                    stratify=reviews.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "tzQqhPbE_fXf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "tzQqhPbE_fXf",
    "outputId": "3aba199c-a5ab-4fd1-b782-c4341adf50b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;calibratedclassifiercv&#x27;,\n",
       "                 CalibratedClassifierCV(estimator=LinearSVC()))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidfvectorizer&#x27;,\n",
       "                 TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                (&#x27;calibratedclassifiercv&#x27;,\n",
       "                 CalibratedClassifierCV(estimator=LinearSVC()))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(analyzer=&#x27;char_wb&#x27;, max_df=0.3, min_df=0.01, ngram_range=(3, 5))</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">calibratedclassifiercv: CalibratedClassifierCV</label><div class=\"sk-toggleable__content\"><pre>CalibratedClassifierCV(estimator=LinearSVC())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='char_wb', max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                ('calibratedclassifiercv',\n",
       "                 CalibratedClassifierCV(estimator=LinearSVC()))])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build with LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=.01, max_df=.3)\n",
    "clf = LinearSVC()\n",
    "#Need that to get probability result for each class\n",
    "calibrated = CalibratedClassifierCV(clf)\n",
    "pipe_tfidf4 = make_pipeline(vec, calibrated)\n",
    "pipe_tfidf4.fit(X_train5, y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "Y4kuzIn3AMlN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4kuzIn3AMlN",
    "outputId": "5b893073-94b4-4699-9b52-ffb712d99e24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mixed       0.60      0.53      0.57      1667\n",
      "    Negative       0.70      0.74      0.72      1666\n",
      "    Positive       0.68      0.73      0.70      1667\n",
      "\n",
      "    accuracy                           0.67      5000\n",
      "   macro avg       0.66      0.67      0.66      5000\n",
      "weighted avg       0.66      0.67      0.66      5000\n",
      "\n",
      "accuracy: 0.665\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe_tfidf4, X_test5, y_test5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o-otaxx4vZEP",
   "metadata": {
    "id": "o-otaxx4vZEP"
   },
   "source": [
    "## Let's combine the all models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ta4CM3IlWqZf",
   "metadata": {
    "id": "ta4CM3IlWqZf"
   },
   "source": [
    "Here we combine models and stack them and get mean for the prediction then get the final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "hJDbJJaHt-HU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJDbJJaHt-HU",
    "outputId": "f8a11403-2cae-4c02-d681-33859a50bb59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here you can add and remove piplines as you want I remove xgboost get a bad result and combine other piplines\n",
    "#You can use any subset of data you want instead X_test1\n",
    "avg_pr = np.stack([proba(pipe,X_test1)\n",
    ",proba(pipe_tfidf,X_test1)\n",
    "  , proba(pipe_tfidf3,X_test1)\n",
    "  ,proba(pipe_tfidf4,X_test1)]).mean(0)\n",
    "avg_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "lt4P30bwv27N",
   "metadata": {
    "id": "lt4P30bwv27N"
   },
   "outputs": [],
   "source": [
    "#Get the index with the highest value as a prediction class\n",
    "index = avg_pr.argmax(axis=1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "zvpQfnQzBJV0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zvpQfnQzBJV0",
    "outputId": "0eca70ce-9a81-4347-e3b5-44017508f62c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Mixed       0.69      0.60      0.64      1667\n",
      "    Negative       0.77      0.77      0.77      1666\n",
      "    Positive       0.72      0.80      0.75      1667\n",
      "\n",
      "    accuracy                           0.73      5000\n",
      "   macro avg       0.72      0.73      0.72      5000\n",
      "weighted avg       0.72      0.72      0.72      5000\n",
      "\n",
      "accuracy: 0.725\n"
     ]
    }
   ],
   "source": [
    "def label_decode(index):\n",
    "    return 'Positive' if index == 2 else 'Negative' if index == 1 else 'Mixed'\n",
    "\n",
    "def print_final_report(index, y_test):\n",
    "    #Get the final report for all stacked models\n",
    "    y_pred = [label_decode(i) for i in index]\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_final_report(index, y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ou3F6-p9Xx9L",
   "metadata": {
    "id": "ou3F6-p9Xx9L"
   },
   "source": [
    "There is a big improve in result using this technic it's like bagging but with different kind of models"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
